{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8cf496",
   "metadata": {},
   "source": [
    "Implementing evaluation mertics on a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c71fb90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install openai\n",
    "# !pip install langchain\n",
    "# !pip install pandas\n",
    "# !pip install -U sentence-transformers\n",
    "# !pip install rdflib\n",
    "# !pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b8f0fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rastegar-a/Documents/GitHub/i-adopt-llm-based-service/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import re\n",
    "from rdflib import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca643a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the folder path\n",
    "# folder_path = \"/Users/rastegar-a/Documents/GitHub/i-adopt-llm-based-service/RDF-modelling-examples/Annotated_variables/\"\n",
    "# # Loop through all files in the folder\n",
    "# for filename in os.listdir(folder_path):\n",
    "#     if filename.endswith(\".csv\"):\n",
    "#         csv_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "#         # Read the CSV file\n",
    "#         df = pd.read_csv(csv_path)\n",
    "        \n",
    "#         # Define JSON output path\n",
    "#         json_filename = filename.replace(\".csv\", \".json\")\n",
    "#         json_path = os.path.join(\"/Users/rastegar-a/Documents/GitHub/i-adopt-llm-based-service/benchmarking_example/\", json_filename)\n",
    "        \n",
    "#         # Convert to JSON\n",
    "#         df.to_json(json_path, orient=\"records\", lines=True)\n",
    "        \n",
    "#         print(f\"Converted {filename} to {json_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84703d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Load from .env file in current directory\n",
    "load_dotenv()\n",
    "\n",
    "# # Get the token from the environment\n",
    "# hf_token = os.getenv(\"hugging_face_api_key\")\n",
    "\n",
    "# # Optional: check if token is loaded\n",
    "# if not hf_token:\n",
    "#     raise ValueError(\"HUGGINGFACE_HUB_TOKEN not found in .env\")\n",
    "\n",
    "# # Login to Hugging Face Hub\n",
    "# login(token=hf_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8305a94a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1) Initialize OpenRouter client (replace <OPENROUTER_API_KEY> with your actual API key).\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),    \n",
    ")\n",
    "\n",
    "# client = OpenAI(\n",
    "#     api_key=os.getenv(\"OPENAI_API_KEY\"),    \n",
    "# )\n",
    "\n",
    "# 2) Folder containing JSON files (each file has one ground-truth variable record)\n",
    "json_folder = \"data/\"\n",
    "# json_folder = \"/Users/rastegar-a/Documents/GitHub/i-adopt-llm-based-service/benchmarking_example/data/one_variable/\"\n",
    "\n",
    "# 3) Models you want to compare on OpenRouter or OpenAI\n",
    "# model_names = [\"deepseek/deepseek-v3-base:free\", \"google/gemini-2.5-pro-exp-03-25:free\"] # OpenRouter models\n",
    "# model_names = [\"deepseek/deepseek-v3-base:free\"] # OpenRouter models\n",
    "# model_names = [\"gpt-4o-mini\", \"gpt-4o\"]\n",
    "model_names = [\"meta-llama/llama-4-scout:free\", \"qwen/qwq-32b:free\"]\n",
    "\n",
    "\n",
    "# 4) Prompt template for asking the model to decompose the variable\n",
    "PROMPT_PATH = \"prompts/prompt_with_examples.txt\"\n",
    "with open(PROMPT_PATH,\"r\") as file:\n",
    "    template = file.read()\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"variable\", \"description\"]\n",
    ")\n",
    "\n",
    "# 5) LLM call helper using OpenRouter's chat endpoint\n",
    "def call_model_openrouter(model_name, user_prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 6) Embedding model (SentenceTransformer) for checking similarity\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def embedding_similarity(text1, text2):\n",
    "    \"\"\"Compute cosine similarity between two pieces of text.\"\"\"\n",
    "    emb1 = embed_model.encode(text1, convert_to_tensor=True)\n",
    "    emb2 = embed_model.encode(text2, convert_to_tensor=True)\n",
    "    return util.cos_sim(emb1, emb2).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e2962d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) We'll evaluate each of these keys with a threshold for correctness\n",
    "# ONTO_KEYS = [\"hasObjectOfInterest\", \"hasProperty\",  \"hasMatrix\", \"hasConstraint\", \"hasContext\"]\n",
    "ONTO_KEYS = [\"hasObjectOfInterest\", \"objectOfInterestURI\", \"hasProperty\", \"hasPropertyURI\", \"hasMatrix\", \"MatrixURI\", \"hasConstraint\", \"ConstraintURI\", \"constrain1\", \"hasContext\", \"ContextURI\"]\n",
    "THRESHOLD = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56c88468",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_confusion_for_field(gt_val, pred_val, threshold=0.90):\n",
    "    \"\"\"\n",
    "    Correct Logic:\n",
    "      True Positive (TP):   GT not empty, pred not empty, similarity >= threshold\n",
    "      False Positive (FP):  GT empty, pred not empty\n",
    "      False Negative (FN):  GT not empty and (pred empty OR similarity < threshold)\n",
    "      True Negative (TN):   GT empty, pred empty\n",
    "    \"\"\"\n",
    "    # Strip leading/trailing whitespace\n",
    "    gt_val = gt_val.strip()\n",
    "    pred_val = pred_val.strip()\n",
    "    \n",
    "    # If ground truth is non-empty => label is \"present\".\n",
    "    if gt_val:\n",
    "        # Prediction non-empty => check similarity\n",
    "        if pred_val:\n",
    "            sim = embedding_similarity(gt_val, pred_val)\n",
    "            if sim >= threshold:\n",
    "                return (1, 0, 0, 0)  # TP\n",
    "            else:\n",
    "                return (0, 0, 1, 0)  # FN (prediction too dissimilar)\n",
    "        else:\n",
    "            # Prediction empty => definitely FN\n",
    "            return (0, 0, 1, 0)\n",
    "    \n",
    "    # If ground truth is empty => label is \"absent\".\n",
    "    else:\n",
    "        if pred_val:\n",
    "            # Predicted something when nothing was needed => FP\n",
    "            return (0, 1, 0, 0)\n",
    "        else:\n",
    "            # Both empty => TN\n",
    "            return (0, 0, 0, 1)\n",
    "\n",
    "    \n",
    "\n",
    "# Helper to compute precision, recall, f1 from confusion matrix totals\n",
    "def precision_recall_f1(tp, fp, fn, tn):\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    if precision + recall == 0:\n",
    "        f1 = 0.0\n",
    "    else:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "099263ad-f1cb-40b2-90b9-8686b37d3d63",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_component(graph, component):\n",
    "    assert component in [\"hasObjectOfInterest\",\"hasProperty\",\"hasMatrix\",\"hasConstraint\",\"hasContext\"]\n",
    "\n",
    "    q = '''\n",
    "        PREFIX iadopt: <https://w3id.org/iadopt/ont/>\n",
    "        \n",
    "        SELECT ?name\n",
    "        WHERE {\n",
    "            ?p rdf:type iadopt:Variable .\n",
    "        \n",
    "            ?p iadopt:{component} ?name .\n",
    "        }\n",
    "    '''\n",
    "    q = q.replace(\"{component}\",component)\n",
    "    \n",
    "    output = None\n",
    "    for r in g.query(q):\n",
    "        ## We should admit multiple hasMatrix, hasContraint, and hasContext. \n",
    "        #if component in [\"hasObjectOfInterest\",\"hasProperty\"]:\n",
    "        if component in [\"hasObjectOfInterest\",\"hasProperty\",\"hasMatrix\",\"hasConstraint\",\"hasContext\"]:\n",
    "            output = r[\"name\"].rsplit('/')[-1]\n",
    "            output = output.rsplit('#')[-1]\n",
    "            break\n",
    "        else:\n",
    "            if output is None:\n",
    "                output = []\n",
    "            output.append(r[\"name\"].replace(\"https://w3id.org/iadopt/ont/\",\"\"))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfd97d98",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 8) Main loop over JSON files\n",
    "all_rows = []  # We'll store row-based results to build a DF\n",
    "\n",
    "for file_name in os.listdir(json_folder):\n",
    "    if file_name.endswith(\".json\"):\n",
    "        with open(os.path.join(json_folder, file_name), \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                data = json.loads(line)\n",
    "\n",
    "                variable_text = data.get(\"Variable\", \"\")\n",
    "                description_text = data.get(\"description\", \"\")\n",
    "                ground_truth = {k: data.get(k, \"\") for k in ONTO_KEYS}\n",
    "                prompt_text = prompt_template.format(\n",
    "                    variable=variable_text,\n",
    "                    description=description_text\n",
    "                )\n",
    "\n",
    "                # For each model, get predictions and compute confusion matrix\n",
    "                for model_name in model_names:\n",
    "                    llm_output = call_model_openrouter(model_name, prompt_text)\n",
    "\n",
    "                    pattern = r\"```(\\w*)\\n(.*?)\\n```\"\n",
    "                    matches = re.findall(pattern, llm_output, re.DOTALL)\n",
    "                    for match in matches:\n",
    "                        language = match[0]\n",
    "                        context = match[1]\n",
    "                        break\n",
    "\n",
    "                    with open(\"output.ttl\",\"w\") as file:\n",
    "                        if \"@prefix : <https://w3id.org/iadopt/ont/> .\" not in context:\n",
    "                            context = \"@prefix : <https://w3id.org/iadopt/ont/> .\\n\" + context\n",
    "                        file.write(context)\n",
    "                    \n",
    "                    g = Graph()\n",
    "                    g.parse(\"output.ttl\",format=\"turtle\") # Maybe if the rdf file cannot be parse retry\n",
    "                    \n",
    "                    predicted_json = {\"hasObjectOfInterest\":None,\"hasProperty\":None, \"hasMatrix\": None, \"hasConstraint\":None, \"hasContext\": None}\n",
    "                    \n",
    "                    for elem in predicted_json:\n",
    "                        predicted_json[elem]=extract_component(g,elem)\n",
    "\n",
    "                    # Accumulate confusion counts across all keys\n",
    "                    total_tp = total_fp = total_fn = total_tn = 0\n",
    "                    for key in ONTO_KEYS:\n",
    "                        gt_val = ground_truth.get(key, \"\") or \"\"\n",
    "                        pred_val = predicted_json.get(key, \"\") or \"\"\n",
    "                        tp, fp, fn, tn = compute_confusion_for_field(gt_val, pred_val)\n",
    "                        total_tp += tp\n",
    "                        total_fp += fp\n",
    "                        total_fn += fn\n",
    "                        total_tn += tn\n",
    "\n",
    "                    prec, rec, f1 = precision_recall_f1(total_tp, total_fp, total_fn, total_tn)\n",
    "\n",
    "                    # Store everything in all_rows, including ground truth & the predicted JSON\n",
    "                    row_dict = {\n",
    "                        \"File\": file_name,\n",
    "                        \"Variable\": variable_text,\n",
    "                        \"Model\": model_name,\n",
    "                        \"TP\": total_tp,\n",
    "                        \"FP\": total_fp,\n",
    "                        \"FN\": total_fn,\n",
    "                        \"TN\": total_tn,\n",
    "                        \"Precision\": round(prec, 3),\n",
    "                        \"Recall\": round(rec, 3),\n",
    "                        \"F1\": round(f1, 3),\n",
    "                        # Store ground truth & predicted as strings for easy reference\n",
    "                        \"GroundTruth\": json.dumps(ground_truth),\n",
    "                        \"LLMOutput\": json.dumps(predicted_json)\n",
    "                    }\n",
    "                    all_rows.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dafb77c6-4735-411f-beae-605001bf49d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Results DataFrame ===\n",
      "\n",
      "          File                                           Variable  \\\n",
      "0    var3.json                                        Cloud cover   \n",
      "1    var3.json                                        Cloud cover   \n",
      "2    var1.json                 Electron density in the solar wind   \n",
      "3    var1.json                 Electron density in the solar wind   \n",
      "4    var5.json  Atmosphere_optical_thickness_due_to_particulat...   \n",
      "5    var5.json  Atmosphere_optical_thickness_due_to_particulat...   \n",
      "6   var17.json  Docosahexaenoic acid content per dry weight (D...   \n",
      "7   var17.json  Docosahexaenoic acid content per dry weight (D...   \n",
      "8    var4.json                 Atmospheric boundary layer heights   \n",
      "9    var4.json                 Atmospheric boundary layer heights   \n",
      "10   var2.json                      Air daily maximum temperature   \n",
      "11   var2.json                      Air daily maximum temperature   \n",
      "\n",
      "                            Model  TP  FP  FN  TN  Precision  Recall     F1  \\\n",
      "0   meta-llama/llama-4-scout:free   0   0   6   5        0.0   0.000  0.000   \n",
      "1               qwen/qwq-32b:free   0   0   6   5        0.0   0.000  0.000   \n",
      "2   meta-llama/llama-4-scout:free   2   0   4   5        1.0   0.333  0.500   \n",
      "3               qwen/qwq-32b:free   3   0   3   5        1.0   0.500  0.667   \n",
      "4   meta-llama/llama-4-scout:free   1   0   7   3        1.0   0.125  0.222   \n",
      "5               qwen/qwq-32b:free   1   1   7   2        0.5   0.125  0.200   \n",
      "6   meta-llama/llama-4-scout:free   1   1   5   4        0.5   0.167  0.250   \n",
      "7               qwen/qwq-32b:free   1   1   5   4        0.5   0.167  0.250   \n",
      "8   meta-llama/llama-4-scout:free   0   0   6   5        0.0   0.000  0.000   \n",
      "9               qwen/qwq-32b:free   0   0   6   5        0.0   0.000  0.000   \n",
      "10  meta-llama/llama-4-scout:free   2   0   7   2        1.0   0.222  0.364   \n",
      "11              qwen/qwq-32b:free   2   0   7   2        1.0   0.222  0.364   \n",
      "\n",
      "                                          GroundTruth  \\\n",
      "0   {\"hasObjectOfInterest\": \"sky\", \"objectOfIntere...   \n",
      "1   {\"hasObjectOfInterest\": \"sky\", \"objectOfIntere...   \n",
      "2   {\"hasObjectOfInterest\": \"electrons\", \"objectOf...   \n",
      "3   {\"hasObjectOfInterest\": \"electrons\", \"objectOf...   \n",
      "4   {\"hasObjectOfInterest\": \"Aerosol\", \"objectOfIn...   \n",
      "5   {\"hasObjectOfInterest\": \"Aerosol\", \"objectOfIn...   \n",
      "6   {\"hasObjectOfInterest\": \"docosahexaenoic acid\"...   \n",
      "7   {\"hasObjectOfInterest\": \"docosahexaenoic acid\"...   \n",
      "8   {\"hasObjectOfInterest\": \"valley floor\", \"objec...   \n",
      "9   {\"hasObjectOfInterest\": \"valley floor\", \"objec...   \n",
      "10  {\"hasObjectOfInterest\": \"air\", \"objectOfIntere...   \n",
      "11  {\"hasObjectOfInterest\": \"air\", \"objectOfIntere...   \n",
      "\n",
      "                                            LLMOutput  \n",
      "0   {\"hasObjectOfInterest\": \"clouds\", \"hasProperty...  \n",
      "1   {\"hasObjectOfInterest\": \"clouds\", \"hasProperty...  \n",
      "2   {\"hasObjectOfInterest\": \"electrons\", \"hasPrope...  \n",
      "3   {\"hasObjectOfInterest\": \"electrons\", \"hasPrope...  \n",
      "4   {\"hasObjectOfInterest\": \"particulate_organic_m...  \n",
      "5   {\"hasObjectOfInterest\": \"particulate_organic_m...  \n",
      "6   {\"hasObjectOfInterest\": \"docosahexaenoic_acid\"...  \n",
      "7   {\"hasObjectOfInterest\": \"docosahexaenoic_acid\"...  \n",
      "8   {\"hasObjectOfInterest\": \"atmospheric_boundary_...  \n",
      "9   {\"hasObjectOfInterest\": \"atmospheric_boundary_...  \n",
      "10  {\"hasObjectOfInterest\": \"air\", \"hasProperty\": ...  \n",
      "11  {\"hasObjectOfInterest\": \"air\", \"hasProperty\": ...  \n",
      "\n",
      "=== Summary (Grouped by File, Model) ===\n",
      "\n",
      "          File                          Model  Precision  Recall     F1\n",
      "0    var1.json  meta-llama/llama-4-scout:free        1.0   0.333  0.500\n",
      "1    var1.json              qwen/qwq-32b:free        1.0   0.500  0.667\n",
      "2   var17.json  meta-llama/llama-4-scout:free        0.5   0.167  0.250\n",
      "3   var17.json              qwen/qwq-32b:free        0.5   0.167  0.250\n",
      "4    var2.json  meta-llama/llama-4-scout:free        1.0   0.222  0.364\n",
      "5    var2.json              qwen/qwq-32b:free        1.0   0.222  0.364\n",
      "6    var3.json  meta-llama/llama-4-scout:free        0.0   0.000  0.000\n",
      "7    var3.json              qwen/qwq-32b:free        0.0   0.000  0.000\n",
      "8    var4.json  meta-llama/llama-4-scout:free        0.0   0.000  0.000\n",
      "9    var4.json              qwen/qwq-32b:free        0.0   0.000  0.000\n",
      "10   var5.json  meta-llama/llama-4-scout:free        1.0   0.125  0.222\n",
      "11   var5.json              qwen/qwq-32b:free        0.5   0.125  0.200\n"
     ]
    }
   ],
   "source": [
    "# 9) Create a DataFrame with aggregated results\n",
    "df_results = pd.DataFrame(all_rows)\n",
    "print(\"\\n=== Final Results DataFrame ===\\n\")\n",
    "print(df_results)\n",
    "\n",
    "# Group by [File, Model] to see average metrics if multiple lines in one file\n",
    "summary = df_results.groupby([\"File\", \"Model\"]).agg({\n",
    "    \"Precision\": \"mean\",\n",
    "    \"Recall\": \"mean\",\n",
    "    \"F1\": \"mean\"\n",
    "}).reset_index()\n",
    "summary = summary.round(3)\n",
    "\n",
    "print(\"\\n=== Summary (Grouped by File, Model) ===\\n\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99e9d3e7-f5a3-4c89-8db9-5a3aade282c0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ground Truth vs. LLM Output Details ===\n",
      "\n",
      "File: var3.json\n",
      "Model: meta-llama/llama-4-scout:free\n",
      "Variable: Cloud cover\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"sky\", \"objectOfInterestURI\": \"https://example.org/ex/sky\", \"hasProperty\": \"cloudiness\", \"hasPropertyURI\": \"https://example.org/cloudiness\", \"hasMatrix\": \"study site\", \"MatrixURI\": \"http://purl.bioontology.org/ontology/LNC/MTHU054795\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": null, \"ContextURI\": null}\n",
      "LLM Output: {\"hasObjectOfInterest\": \"clouds\", \"hasProperty\": \"cloud_cover\", \"hasMatrix\": null, \"hasConstraint\": null, \"hasContext\": null}\n",
      "--------------------------------------------------\n",
      "File: var3.json\n",
      "Model: qwen/qwq-32b:free\n",
      "Variable: Cloud cover\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"sky\", \"objectOfInterestURI\": \"https://example.org/ex/sky\", \"hasProperty\": \"cloudiness\", \"hasPropertyURI\": \"https://example.org/cloudiness\", \"hasMatrix\": \"study site\", \"MatrixURI\": \"http://purl.bioontology.org/ontology/LNC/MTHU054795\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": null, \"ContextURI\": null}\n",
      "LLM Output: {\"hasObjectOfInterest\": \"clouds\", \"hasProperty\": \"cloudCover\", \"hasMatrix\": \"study_site\", \"hasConstraint\": null, \"hasContext\": null}\n",
      "--------------------------------------------------\n",
      "File: var1.json\n",
      "Model: meta-llama/llama-4-scout:free\n",
      "Variable: Electron density in the solar wind\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"electrons\", \"objectOfInterestURI\": \"http://purl.bioontology.org/ontology/LNC/LA3953-2\", \"hasProperty\": \"density\", \"hasPropertyURI\": \"http://www.ontology-of-units-of-measure.org/resource/om-2/Density\", \"hasMatrix\": \"Solar Wind\", \"MatrixURI\": \"http://sweetontology.net/phenHelio/SolarWind\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": null, \"ContextURI\": null}\n",
      "LLM Output: {\"hasObjectOfInterest\": \"electrons\", \"hasProperty\": \"density\", \"hasMatrix\": null, \"hasConstraint\": null, \"hasContext\": null}\n",
      "--------------------------------------------------\n",
      "File: var1.json\n",
      "Model: qwen/qwq-32b:free\n",
      "Variable: Electron density in the solar wind\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"electrons\", \"objectOfInterestURI\": \"http://purl.bioontology.org/ontology/LNC/LA3953-2\", \"hasProperty\": \"density\", \"hasPropertyURI\": \"http://www.ontology-of-units-of-measure.org/resource/om-2/Density\", \"hasMatrix\": \"Solar Wind\", \"MatrixURI\": \"http://sweetontology.net/phenHelio/SolarWind\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": null, \"ContextURI\": null}\n",
      "LLM Output: {\"hasObjectOfInterest\": \"electrons\", \"hasProperty\": \"density\", \"hasMatrix\": \"solar_wind\", \"hasConstraint\": null, \"hasContext\": null}\n",
      "--------------------------------------------------\n",
      "File: var5.json\n",
      "Model: meta-llama/llama-4-scout:free\n",
      "Variable: Atmosphere_optical_thickness_due_to_particulate_organic_matter_ambient_aerosol\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"Aerosol\", \"objectOfInterestURI\": \"http://purl.bioontology.org/ontology/SNOMEDCT/64242006\", \"hasProperty\": \"Optical Thickness\", \"hasPropertyURI\": \"http://sweetontology.net/propSpaceThickness/OpticalThickness\", \"hasMatrix\": \"Atmosphere\", \"MatrixURI\": \"http://purl.bioontology.org/ontology/SNOMEDCT/304607008\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": \"Path of Radiation\", \"ContextURI\": \"http://www.example.org/path_of_radition\"}\n",
      "LLM Output: {\"hasObjectOfInterest\": \"particulate_organic_matter\", \"hasProperty\": \"optical_thickness\", \"hasMatrix\": null, \"hasConstraint\": null, \"hasContext\": null}\n",
      "--------------------------------------------------\n",
      "File: var5.json\n",
      "Model: qwen/qwq-32b:free\n",
      "Variable: Atmosphere_optical_thickness_due_to_particulate_organic_matter_ambient_aerosol\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"Aerosol\", \"objectOfInterestURI\": \"http://purl.bioontology.org/ontology/SNOMEDCT/64242006\", \"hasProperty\": \"Optical Thickness\", \"hasPropertyURI\": \"http://sweetontology.net/propSpaceThickness/OpticalThickness\", \"hasMatrix\": \"Atmosphere\", \"MatrixURI\": \"http://purl.bioontology.org/ontology/SNOMEDCT/304607008\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": \"Path of Radiation\", \"ContextURI\": \"http://www.example.org/path_of_radition\"}\n",
      "LLM Output: {\"hasObjectOfInterest\": \"particulate_organic_matter\", \"hasProperty\": \"optical_thickness\", \"hasMatrix\": \"aerosol\", \"hasConstraint\": \"ambient\", \"hasContext\": null}\n",
      "--------------------------------------------------\n",
      "File: var17.json\n",
      "Model: meta-llama/llama-4-scout:free\n",
      "Variable: Docosahexaenoic acid content per dry weight (DHA content/ C22:6 n-3 content)\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"docosahexaenoic acid\", \"objectOfInterestURI\": \"http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#C68345\", \"hasProperty\": \"relative dry weight\", \"hasPropertyURI\": \"http://purl.obolibrary.org/obo/TO_0000633\", \"hasMatrix\": \"individual\", \"MatrixURI\": \"http://www.ebi.ac.uk/efo/EFO_0000542\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": null, \"ContextURI\": null}\n",
      "LLM Output: {\"hasObjectOfInterest\": \"docosahexaenoic_acid\", \"hasProperty\": \"content\", \"hasMatrix\": null, \"hasConstraint\": \"dry_weight\", \"hasContext\": null}\n",
      "--------------------------------------------------\n",
      "File: var17.json\n",
      "Model: qwen/qwq-32b:free\n",
      "Variable: Docosahexaenoic acid content per dry weight (DHA content/ C22:6 n-3 content)\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"docosahexaenoic acid\", \"objectOfInterestURI\": \"http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#C68345\", \"hasProperty\": \"relative dry weight\", \"hasPropertyURI\": \"http://purl.obolibrary.org/obo/TO_0000633\", \"hasMatrix\": \"individual\", \"MatrixURI\": \"http://www.ebi.ac.uk/efo/EFO_0000542\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": null, \"ContextURI\": null}\n",
      "LLM Output: {\"hasObjectOfInterest\": \"docosahexaenoic_acid\", \"hasProperty\": \"content\", \"hasMatrix\": \"individual_organism\", \"hasConstraint\": \"dry_weight\", \"hasContext\": null}\n",
      "--------------------------------------------------\n",
      "File: var4.json\n",
      "Model: meta-llama/llama-4-scout:free\n",
      "Variable: Atmospheric boundary layer heights\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"valley floor\", \"objectOfInterestURI\": \"https://example.org/valley_floor\", \"hasProperty\": \"height-range\", \"hasPropertyURI\": \"http://sweetontology.net/propSpaceHeight/HeightRange\", \"hasMatrix\": \"Boundary Layer/Free Troposphere\", \"MatrixURI\": \"http://sweetontology.net/realmAtmo/FreeTroposphere\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": null, \"ContextURI\": null}\n",
      "LLM Output: {\"hasObjectOfInterest\": \"atmospheric_boundary_layer\", \"hasProperty\": \"height\", \"hasMatrix\": null, \"hasConstraint\": null, \"hasContext\": null}\n",
      "--------------------------------------------------\n",
      "File: var4.json\n",
      "Model: qwen/qwq-32b:free\n",
      "Variable: Atmospheric boundary layer heights\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"valley floor\", \"objectOfInterestURI\": \"https://example.org/valley_floor\", \"hasProperty\": \"height-range\", \"hasPropertyURI\": \"http://sweetontology.net/propSpaceHeight/HeightRange\", \"hasMatrix\": \"Boundary Layer/Free Troposphere\", \"MatrixURI\": \"http://sweetontology.net/realmAtmo/FreeTroposphere\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": null, \"ContextURI\": null}\n",
      "LLM Output: {\"hasObjectOfInterest\": \"atmospheric_boundary_layer\", \"hasProperty\": \"height\", \"hasMatrix\": \"valley_floor\", \"hasConstraint\": null, \"hasContext\": null}\n",
      "--------------------------------------------------\n",
      "File: var2.json\n",
      "Model: meta-llama/llama-4-scout:free\n",
      "Variable: Air daily maximum temperature\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"air\", \"objectOfInterestURI\": \"http://purl.obolibrary.org/obo/ENVO_00002005\", \"hasProperty\": \"Temperature \", \"hasPropertyURI\": \"http://ecoinformatics.org/oboe/oboe.1.2/oboe-characteristics.owl#Temperature\", \"hasMatrix\": null, \"MatrixURI\": null, \"hasConstraint\": \"height\", \"ConstraintURI\": \"http://www.ontology-of-units-of-measure.org/resource/om-2/Height\", \"constrain1\": \"air\", \"hasContext\": \"daily maximum air temperature\", \"ContextURI\": \"http://purl.obolibrary.org/obo/ECOSIM_TAMX\"}\n",
      "LLM Output: {\"hasObjectOfInterest\": \"air\", \"hasProperty\": \"temperature\", \"hasMatrix\": null, \"hasConstraint\": \"daily_maximum\", \"hasContext\": null}\n",
      "--------------------------------------------------\n",
      "File: var2.json\n",
      "Model: qwen/qwq-32b:free\n",
      "Variable: Air daily maximum temperature\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"air\", \"objectOfInterestURI\": \"http://purl.obolibrary.org/obo/ENVO_00002005\", \"hasProperty\": \"Temperature \", \"hasPropertyURI\": \"http://ecoinformatics.org/oboe/oboe.1.2/oboe-characteristics.owl#Temperature\", \"hasMatrix\": null, \"MatrixURI\": null, \"hasConstraint\": \"height\", \"ConstraintURI\": \"http://www.ontology-of-units-of-measure.org/resource/om-2/Height\", \"constrain1\": \"air\", \"hasContext\": \"daily maximum air temperature\", \"ContextURI\": \"http://purl.obolibrary.org/obo/ECOSIM_TAMX\"}\n",
      "LLM Output: {\"hasObjectOfInterest\": \"air\", \"hasProperty\": \"temperature\", \"hasMatrix\": null, \"hasConstraint\": \"1_7_meter_height\", \"hasContext\": null}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 10) Finally, show ground truth and LLM outputs after the summary\n",
    "print(\"\\n=== Ground Truth vs. LLM Output Details ===\\n\")\n",
    "for idx, row in df_results.iterrows():\n",
    "    print(\"File:\", row[\"File\"])\n",
    "    print(\"Model:\", row[\"Model\"])\n",
    "    print(\"Variable:\", row[\"Variable\"])\n",
    "    print(\"Ground Truth:\", row[\"GroundTruth\"])\n",
    "    print(\"LLM Output:\", row[\"LLMOutput\"])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e728c7-18d6-4584-8c5e-45ad6eb5c3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
