{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8cf496",
   "metadata": {},
   "source": [
    "Implementing evaluation mertics on a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c71fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai\n",
    "# !pip install langchain\n",
    "# !pip install pandas\n",
    "# !pip install -U sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b8f0fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca643a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the folder path\n",
    "# folder_path = \"/Users/rastegar-a/Documents/GitHub/i-adopt-llm-based-service/RDF-modelling-examples/Annotated_variables/\"\n",
    "# # Loop through all files in the folder\n",
    "# for filename in os.listdir(folder_path):\n",
    "#     if filename.endswith(\".csv\"):\n",
    "#         csv_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "#         # Read the CSV file\n",
    "#         df = pd.read_csv(csv_path)\n",
    "        \n",
    "#         # Define JSON output path\n",
    "#         json_filename = filename.replace(\".csv\", \".json\")\n",
    "#         json_path = os.path.join(\"/Users/rastegar-a/Documents/GitHub/i-adopt-llm-based-service/benchmarking_example/\", json_filename)\n",
    "        \n",
    "#         # Convert to JSON\n",
    "#         df.to_json(json_path, orient=\"records\", lines=True)\n",
    "        \n",
    "#         print(f\"Converted {filename} to {json_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84703d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Load from .env file in current directory\n",
    "load_dotenv()\n",
    "\n",
    "# Get the token from the environment\n",
    "hf_token = os.getenv(\"hugging_face_api_key\")\n",
    "\n",
    "# Optional: check if token is loaded\n",
    "if not hf_token:\n",
    "    raise ValueError(\"HUGGINGFACE_HUB_TOKEN not found in .env\")\n",
    "\n",
    "# Login to Hugging Face Hub\n",
    "login(token=hf_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8305a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Initialize OpenRouter client (replace <OPENROUTER_API_KEY> with your actual API key).\n",
    "# client = OpenAI(\n",
    "#     base_url=\"https://openrouter.ai/api/v1\",\n",
    "#     api_key=os.getenv(\"OPENROUTER_API_KEY\"),    \n",
    "# )\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),    \n",
    ")\n",
    "\n",
    "# 2) Folder containing JSON files (each file has one ground-truth variable record)\n",
    "json_folder = \"/Users/rastegar-a/Documents/GitHub/i-adopt-llm-based-service/benchmarking_example/data/\"\n",
    "# json_folder = \"/Users/rastegar-a/Documents/GitHub/i-adopt-llm-based-service/benchmarking_example/data/one_variable/\"\n",
    "\n",
    "# 3) Models you want to compare on OpenRouter or OpenAI\n",
    "# model_names = [\"deepseek/deepseek-v3-base:free\", \"google/gemini-2.5-pro-exp-03-25:free\"] # OpenRouter models\n",
    "# model_names = [\"deepseek/deepseek-v3-base:free\"] # OpenRouter models\n",
    "model_names = [\"gpt-4o-mini\", \"gpt-4o\"]\n",
    "\n",
    "\n",
    "# 4) Prompt template for asking the model to decompose the variable\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "Example:\n",
    "Variable: Peak ground acceleration\n",
    "Description: Peak acceleration measured on the earth surface when facing seismic events, like earthquakes. \n",
    "hasObjectOfInterest: ground\n",
    "objectOfInterestURI: http://vocabs.lter-europe.net/EnvThes/30365\n",
    "hasProperty: acceleration\n",
    "hasPropertyURI: https://qudt.org/vocab/quantitykind/Acceleration\n",
    "hasMatrix: earth suface\n",
    "MatrixURI: http://purl.obolibrary.org/obo/RBO_00000017\n",
    "hasConstraint: null\n",
    "ConstraintURI: null\n",
    "constrain1: null\n",
    "hasContext: seismic event\n",
    "ContextURI: https://terra-vocabulary.org/ncl/FAIR-Incubator/earthfeaturetype/c_07d7a262\n",
    "\n",
    "You are a system that decomposes scientific variables into I-ADOPT ontology components. Given the example above. \n",
    "The I-ADOPT Framework defines four classes or \"concepts\" (Variable, Property, Entity, Constraint), and six object properties (hasProperty, hasObjectOfInterest, hasContextObject, hasMatrix, hasConstraint, constrains). The Variable is the top concept. It represents the description of something observed or mathematically derived. It minimally consists of one entity (the ObjectOfInterest) and its Property; a Property being a type of characteristic (i.e. a quantity or a quality). More complex variables can involve additional entities, for example an entity may have the role of Matrix and/or of ContextObject(s). The framework does not capture units, instruments, methods, and geographical location information.\n",
    "Variable: {variable}\n",
    "Description: {description}\n",
    "\n",
    "Decompose it into:\n",
    "- hasObjectOfInterest\n",
    "- objectOfInterestURI --OPTIONAL--\n",
    "- hasProperty\n",
    "- hasPropertyURI --OPTIONAL--\n",
    "- hasMatrix --OPTIONAL--\n",
    "- MatrixURI --OPTIONAL--\n",
    "- hasConstraint --OPTIONAL--\n",
    "- ConstraintURI --OPTIONAL--\n",
    "- constrain1 --OPTIONAL--\n",
    "- hasContext --OPTIONAL--\n",
    "- ContextURI --OPTIONAL--\n",
    "\n",
    "Return a JSON in this exact format:\n",
    "{{\n",
    "  \"Variable\": \"...\",\n",
    "  \"hasObjectOfInterest\": \"...\",\n",
    "  \"objectOfInterestURI\": \"...\",\n",
    "  \"hasProperty\": \"...\", \n",
    "  \"hasPropertyURI\": \"...\",\n",
    "  \"hasMatrix\": \"...\",\n",
    "  \"MatrixURI\": \"...\",\n",
    "  \"hasConstraint\": \"...\",\n",
    "  \"ConstraintURI\": \"...\",\n",
    "  \"constrain1\": \"...\",\n",
    "  \"hasContext\": \"...\"\n",
    "  \"ContextURI\": \"...\",\n",
    "}}\n",
    "\"\"\",\n",
    "    input_variables=[\"variable\", \"description\"]\n",
    ")\n",
    "\n",
    "# 5) LLM call helper using OpenRouter's chat endpoint\n",
    "def call_model_openrouter(model_name, user_prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        extra_headers={\n",
    "            \"HTTP-Referer\": \"<YOUR_SITE_URL>\",  # optional\n",
    "            \"X-Title\": \"<YOUR_SITE_NAME>\"       # optional\n",
    "        },\n",
    "        model=model_name,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 6) Embedding model (SentenceTransformer) for checking similarity\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def embedding_similarity(text1, text2):\n",
    "    \"\"\"Compute cosine similarity between two pieces of text.\"\"\"\n",
    "    emb1 = embed_model.encode(text1, convert_to_tensor=True)\n",
    "    emb2 = embed_model.encode(text2, convert_to_tensor=True)\n",
    "    return util.cos_sim(emb1, emb2).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050b6ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e2962d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) We'll evaluate each of these keys with a threshold for correctness\n",
    "# ONTO_KEYS = [\"hasObjectOfInterest\", \"hasProperty\",  \"hasMatrix\", \"hasConstraint\", \"hasContext\"]\n",
    "ONTO_KEYS = [\"hasObjectOfInterest\", \"objectOfInterestURI\", \"hasProperty\", \"hasPropertyURI\", \"hasMatrix\", \"MatrixURI\", \"hasConstraint\", \"ConstraintURI\", \"constrain1\", \"hasContext\", \"ContextURI\"]\n",
    "THRESHOLD = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56c88468",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_confusion_for_field(gt_val, pred_val, threshold=0.90):\n",
    "    \"\"\"\n",
    "    Correct Logic:\n",
    "      True Positive (TP):   GT not empty, pred not empty, similarity >= threshold\n",
    "      False Positive (FP):  GT empty, pred not empty\n",
    "      False Negative (FN):  GT not empty and (pred empty OR similarity < threshold)\n",
    "      True Negative (TN):   GT empty, pred empty\n",
    "    \"\"\"\n",
    "    # Strip leading/trailing whitespace\n",
    "    gt_val = gt_val.strip()\n",
    "    pred_val = pred_val.strip()\n",
    "    \n",
    "    # If ground truth is non-empty => label is \"present\".\n",
    "    if gt_val:\n",
    "        # Prediction non-empty => check similarity\n",
    "        if pred_val:\n",
    "            sim = embedding_similarity(gt_val, pred_val)\n",
    "            if sim >= threshold:\n",
    "                return (1, 0, 0, 0)  # TP\n",
    "            else:\n",
    "                return (0, 0, 1, 0)  # FN (prediction too dissimilar)\n",
    "        else:\n",
    "            # Prediction empty => definitely FN\n",
    "            return (0, 0, 1, 0)\n",
    "    \n",
    "    # If ground truth is empty => label is \"absent\".\n",
    "    else:\n",
    "        if pred_val:\n",
    "            # Predicted something when nothing was needed => FP\n",
    "            return (0, 1, 0, 0)\n",
    "        else:\n",
    "            # Both empty => TN\n",
    "            return (0, 0, 0, 1)\n",
    "\n",
    "    \n",
    "\n",
    "# Helper to compute precision, recall, f1 from confusion matrix totals\n",
    "def precision_recall_f1(tp, fp, fn, tn):\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    if precision + recall == 0:\n",
    "        f1 = 0.0\n",
    "    else:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cfd97d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Main loop over JSON files\n",
    "all_rows = []  # We'll store row-based results to build a DF\n",
    "\n",
    "for file_name in os.listdir(json_folder):\n",
    "    if file_name.endswith(\".json\"):\n",
    "        with open(os.path.join(json_folder, file_name), \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                data = json.loads(line)\n",
    "\n",
    "                variable_text = data.get(\"Variable\", \"\")\n",
    "                description_text = data.get(\"description\", \"\")\n",
    "                ground_truth = {k: data.get(k, \"\") for k in ONTO_KEYS}\n",
    "                prompt_text = prompt_template.format(\n",
    "                    variable=variable_text,\n",
    "                    description=description_text\n",
    "                )\n",
    "\n",
    "                # For each model, get predictions and compute confusion matrix\n",
    "                for model_name in model_names:\n",
    "                    llm_output = call_model_openrouter(model_name, prompt_text)\n",
    "                    # --- Remove code fences if present ---\n",
    "                    # This will remove any ``` or ```json lines\n",
    "                    cleaned_output = re.sub(r\"```(\\w+)?\", \"\", llm_output).strip()\n",
    "\n",
    "                    # Attempt to parse the cleaned string as JSON\n",
    "                    predicted_json = json.loads(cleaned_output)\n",
    "\n",
    "                    # Accumulate confusion counts across all keys\n",
    "                    total_tp = total_fp = total_fn = total_tn = 0\n",
    "                    for key in ONTO_KEYS:\n",
    "                        gt_val = ground_truth.get(key, \"\") or \"\"\n",
    "                        pred_val = predicted_json.get(key, \"\") or \"\"\n",
    "                        tp, fp, fn, tn = compute_confusion_for_field(gt_val, pred_val)\n",
    "                        total_tp += tp\n",
    "                        total_fp += fp\n",
    "                        total_fn += fn\n",
    "                        total_tn += tn\n",
    "\n",
    "                    prec, rec, f1 = precision_recall_f1(total_tp, total_fp, total_fn, total_tn)\n",
    "\n",
    "                    # Store everything in all_rows, including ground truth & the predicted JSON\n",
    "                    row_dict = {\n",
    "                        \"File\": file_name,\n",
    "                        \"Variable\": variable_text,\n",
    "                        \"Model\": model_name,\n",
    "                        \"TP\": total_tp,\n",
    "                        \"FP\": total_fp,\n",
    "                        \"FN\": total_fn,\n",
    "                        \"TN\": total_tn,\n",
    "                        \"Precision\": round(prec, 3),\n",
    "                        \"Recall\": round(rec, 3),\n",
    "                        \"F1\": round(f1, 3),\n",
    "                        # Store ground truth & predicted as strings for easy reference\n",
    "                        \"GroundTruth\": json.dumps(ground_truth),\n",
    "                        \"LLMOutput\": json.dumps(predicted_json)\n",
    "                    }\n",
    "                    all_rows.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f00dfa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Results DataFrame ===\n",
      "\n",
      "          File                                           Variable  \\\n",
      "0    var1.json                 Electron density in the solar wind   \n",
      "1    var1.json                 Electron density in the solar wind   \n",
      "2    var3.json                                        Cloud cover   \n",
      "3    var3.json                                        Cloud cover   \n",
      "4    var2.json                      Air daily maximum temperature   \n",
      "5    var2.json                      Air daily maximum temperature   \n",
      "6   var17.json  Docosahexaenoic acid content per dry weight (D...   \n",
      "7   var17.json  Docosahexaenoic acid content per dry weight (D...   \n",
      "8    var5.json  Atmosphere_optical_thickness_due_to_particulat...   \n",
      "9    var5.json  Atmosphere_optical_thickness_due_to_particulat...   \n",
      "10   var4.json                 Atmospheric boundary layer heights   \n",
      "11   var4.json                 Atmospheric boundary layer heights   \n",
      "\n",
      "          Model  TP  FP  FN  TN  Precision  Recall     F1  \\\n",
      "0   gpt-4o-mini   1   2   5   3      0.333   0.167  0.222   \n",
      "1        gpt-4o   3   0   3   5      1.000   0.500  0.667   \n",
      "2   gpt-4o-mini   3   0   3   5      1.000   0.500  0.667   \n",
      "3        gpt-4o   0   2   6   3      0.000   0.000  0.000   \n",
      "4   gpt-4o-mini   2   2   7   0      0.500   0.222  0.308   \n",
      "5        gpt-4o   3   2   6   0      0.600   0.333  0.429   \n",
      "6   gpt-4o-mini   0   5   6   0      0.000   0.000  0.000   \n",
      "7        gpt-4o   1   1   5   4      0.500   0.167  0.250   \n",
      "8   gpt-4o-mini   1   3   7   0      0.250   0.125  0.167   \n",
      "9        gpt-4o   1   0   7   3      1.000   0.125  0.222   \n",
      "10  gpt-4o-mini   1   5   5   0      0.167   0.167  0.167   \n",
      "11       gpt-4o   0   1   6   4      0.000   0.000  0.000   \n",
      "\n",
      "                                          GroundTruth  \\\n",
      "0   {\"hasObjectOfInterest\": \"electrons\", \"objectOf...   \n",
      "1   {\"hasObjectOfInterest\": \"electrons\", \"objectOf...   \n",
      "2   {\"hasObjectOfInterest\": \"sky\", \"objectOfIntere...   \n",
      "3   {\"hasObjectOfInterest\": \"sky\", \"objectOfIntere...   \n",
      "4   {\"hasObjectOfInterest\": \"air\", \"objectOfIntere...   \n",
      "5   {\"hasObjectOfInterest\": \"air\", \"objectOfIntere...   \n",
      "6   {\"hasObjectOfInterest\": \"docosahexaenoic acid\"...   \n",
      "7   {\"hasObjectOfInterest\": \"docosahexaenoic acid\"...   \n",
      "8   {\"hasObjectOfInterest\": \"Aerosol\", \"objectOfIn...   \n",
      "9   {\"hasObjectOfInterest\": \"Aerosol\", \"objectOfIn...   \n",
      "10  {\"hasObjectOfInterest\": \"valley floor\", \"objec...   \n",
      "11  {\"hasObjectOfInterest\": \"valley floor\", \"objec...   \n",
      "\n",
      "                                            LLMOutput  \n",
      "0   {\"Variable\": \"Electron density in the solar wi...  \n",
      "1   {\"Variable\": \"Electron density in the solar wi...  \n",
      "2   {\"Variable\": \"Cloud cover\", \"hasObjectOfIntere...  \n",
      "3   {\"Variable\": \"Cloud cover\", \"hasObjectOfIntere...  \n",
      "4   {\"Variable\": \"Air daily maximum temperature\", ...  \n",
      "5   {\"Variable\": \"Air daily maximum temperature\", ...  \n",
      "6   {\"Variable\": \"Docosahexaenoic acid content per...  \n",
      "7   {\"Variable\": \"Docosahexaenoic acid content per...  \n",
      "8   {\"Variable\": \"Atmosphere_optical_thickness_due...  \n",
      "9   {\"Variable\": \"Atmosphere_optical_thickness_due...  \n",
      "10  {\"Variable\": \"Atmospheric boundary layer heigh...  \n",
      "11  {\"Variable\": \"Atmospheric boundary layer heigh...  \n",
      "\n",
      "=== Summary (Grouped by File, Model) ===\n",
      "\n",
      "          File        Model  Precision  Recall     F1\n",
      "0    var1.json       gpt-4o      1.000   0.500  0.667\n",
      "1    var1.json  gpt-4o-mini      0.333   0.167  0.222\n",
      "2   var17.json       gpt-4o      0.500   0.167  0.250\n",
      "3   var17.json  gpt-4o-mini      0.000   0.000  0.000\n",
      "4    var2.json       gpt-4o      0.600   0.333  0.429\n",
      "5    var2.json  gpt-4o-mini      0.500   0.222  0.308\n",
      "6    var3.json       gpt-4o      0.000   0.000  0.000\n",
      "7    var3.json  gpt-4o-mini      1.000   0.500  0.667\n",
      "8    var4.json       gpt-4o      0.000   0.000  0.000\n",
      "9    var4.json  gpt-4o-mini      0.167   0.167  0.167\n",
      "10   var5.json       gpt-4o      1.000   0.125  0.222\n",
      "11   var5.json  gpt-4o-mini      0.250   0.125  0.167\n"
     ]
    }
   ],
   "source": [
    "# 9) Create a DataFrame with aggregated results\n",
    "df_results = pd.DataFrame(all_rows)\n",
    "print(\"\\n=== Final Results DataFrame ===\\n\")\n",
    "print(df_results)\n",
    "\n",
    "# Group by [File, Model] to see average metrics if multiple lines in one file\n",
    "summary = df_results.groupby([\"File\", \"Model\"]).agg({\n",
    "    \"Precision\": \"mean\",\n",
    "    \"Recall\": \"mean\",\n",
    "    \"F1\": \"mean\"\n",
    "}).reset_index()\n",
    "summary = summary.round(3)\n",
    "\n",
    "print(\"\\n=== Summary (Grouped by File, Model) ===\\n\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d9a186b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ground Truth vs. LLM Output Details ===\n",
      "\n",
      "File: var1.json\n",
      "Model: gpt-4o-mini\n",
      "Variable: Electron density in the solar wind\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"electrons\", \"objectOfInterestURI\": \"http://purl.bioontology.org/ontology/LNC/LA3953-2\", \"hasProperty\": \"density\", \"hasPropertyURI\": \"http://www.ontology-of-units-of-measure.org/resource/om-2/Density\", \"hasMatrix\": \"Solar Wind\", \"MatrixURI\": \"http://sweetontology.net/phenHelio/SolarWind\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": null, \"ContextURI\": null}\n",
      "LLM Output: {\"Variable\": \"Electron density in the solar wind\", \"hasObjectOfInterest\": \"solar wind\", \"objectOfInterestURI\": \"http://example.org/solarwind\", \"hasProperty\": \"density\", \"hasPropertyURI\": \"https://qudt.org/vocab/quantitykind/Density\", \"hasMatrix\": \"none\", \"MatrixURI\": \"\", \"hasConstraint\": \"none\", \"ConstraintURI\": \"\", \"constrain1\": \"\", \"hasContext\": \"none\", \"ContextURI\": \"\"}\n",
      "--------------------------------------------------\n",
      "File: var1.json\n",
      "Model: gpt-4o\n",
      "Variable: Electron density in the solar wind\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"electrons\", \"objectOfInterestURI\": \"http://purl.bioontology.org/ontology/LNC/LA3953-2\", \"hasProperty\": \"density\", \"hasPropertyURI\": \"http://www.ontology-of-units-of-measure.org/resource/om-2/Density\", \"hasMatrix\": \"Solar Wind\", \"MatrixURI\": \"http://sweetontology.net/phenHelio/SolarWind\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": null, \"ContextURI\": null}\n",
      "LLM Output: {\"Variable\": \"Electron density in the solar wind\", \"hasObjectOfInterest\": \"electrons\", \"objectOfInterestURI\": \"\", \"hasProperty\": \"density\", \"hasPropertyURI\": \"https://qudt.org/vocab/quantitykind/NumberDensity\", \"hasMatrix\": \"solar wind\", \"MatrixURI\": \"http://purl.obolibrary.org/obo/ENVO_01001234\", \"hasConstraint\": \"\", \"ConstraintURI\": \"\", \"constrain1\": \"\", \"hasContext\": \"\", \"ContextURI\": \"\"}\n",
      "--------------------------------------------------\n",
      "File: var3.json\n",
      "Model: gpt-4o-mini\n",
      "Variable: Cloud cover\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"sky\", \"objectOfInterestURI\": \"https://example.org/ex/sky\", \"hasProperty\": \"cloudiness\", \"hasPropertyURI\": \"https://example.org/cloudiness\", \"hasMatrix\": \"study site\", \"MatrixURI\": \"http://purl.bioontology.org/ontology/LNC/MTHU054795\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": null, \"ContextURI\": null}\n",
      "LLM Output: {\"Variable\": \"Cloud cover\", \"hasObjectOfInterest\": \"sky\", \"objectOfInterestURI\": \"http://vocabs.lter-europe.net/EnvThes/30366\", \"hasProperty\": \"cloudiness\", \"hasPropertyURI\": \"https://qudt.org/vocab/quantitykind/Cloudiness\", \"hasMatrix\": \"study site\", \"MatrixURI\": \"http://purl.obolibrary.org/obo/RBO_00000018\", \"hasConstraint\": \"\", \"ConstraintURI\": \"\", \"constrain1\": \"\", \"hasContext\": \"\", \"ContextURI\": \"\"}\n",
      "--------------------------------------------------\n",
      "File: var3.json\n",
      "Model: gpt-4o\n",
      "Variable: Cloud cover\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"sky\", \"objectOfInterestURI\": \"https://example.org/ex/sky\", \"hasProperty\": \"cloudiness\", \"hasPropertyURI\": \"https://example.org/cloudiness\", \"hasMatrix\": \"study site\", \"MatrixURI\": \"http://purl.bioontology.org/ontology/LNC/MTHU054795\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": null, \"ContextURI\": null}\n",
      "LLM Output: {\"Variable\": \"Cloud cover\", \"hasObjectOfInterest\": \"cloud\", \"objectOfInterestURI\": \"http://vocab.nerc.ac.uk/collection/P07/current/CFSN0023/\", \"hasProperty\": \"amount\", \"hasPropertyURI\": \"http://qudt.org/vocab/quantitykind/AmountOfSubstance\", \"hasMatrix\": \"sky\", \"MatrixURI\": \"http://purl.obolibrary.org/obo/ENVO_01000813\", \"hasConstraint\": \"\", \"ConstraintURI\": \"\", \"constrain1\": \"\", \"hasContext\": \"study site\", \"ContextURI\": \"http://vocab.nerc.ac.uk/collection/P07/current/CFSN0023/\"}\n",
      "--------------------------------------------------\n",
      "File: var2.json\n",
      "Model: gpt-4o-mini\n",
      "Variable: Air daily maximum temperature\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"air\", \"objectOfInterestURI\": \"http://purl.obolibrary.org/obo/ENVO_00002005\", \"hasProperty\": \"Temperature \", \"hasPropertyURI\": \"http://ecoinformatics.org/oboe/oboe.1.2/oboe-characteristics.owl#Temperature\", \"hasMatrix\": null, \"MatrixURI\": null, \"hasConstraint\": \"height\", \"ConstraintURI\": \"http://www.ontology-of-units-of-measure.org/resource/om-2/Height\", \"constrain1\": \"air\", \"hasContext\": \"daily maximum air temperature\", \"ContextURI\": \"http://purl.obolibrary.org/obo/ECOSIM_TAMX\"}\n",
      "LLM Output: {\"Variable\": \"Air daily maximum temperature\", \"hasObjectOfInterest\": \"air\", \"objectOfInterestURI\": \"http://vocabs.lter-europe.net/EnvThes/30366\", \"hasProperty\": \"temperature\", \"hasPropertyURI\": \"https://qudt.org/vocab/quantitykind/Temperature\", \"hasMatrix\": \"1.7 meters\", \"MatrixURI\": \"http://purl.obolibrary.org/obo/RBO_00000018\", \"hasConstraint\": \"daily maximum\", \"ConstraintURI\": \"http://example.org/constraints/daily_maximum\", \"constrain1\": \"maximum temperature recorded in a day\", \"hasContext\": \"daily measurement\", \"ContextURI\": \"https://terra-vocabulary.org/ncl/FAIR-Incubator/earthfeaturetype/c_07d7a263\"}\n",
      "--------------------------------------------------\n",
      "File: var2.json\n",
      "Model: gpt-4o\n",
      "Variable: Air daily maximum temperature\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"air\", \"objectOfInterestURI\": \"http://purl.obolibrary.org/obo/ENVO_00002005\", \"hasProperty\": \"Temperature \", \"hasPropertyURI\": \"http://ecoinformatics.org/oboe/oboe.1.2/oboe-characteristics.owl#Temperature\", \"hasMatrix\": null, \"MatrixURI\": null, \"hasConstraint\": \"height\", \"ConstraintURI\": \"http://www.ontology-of-units-of-measure.org/resource/om-2/Height\", \"constrain1\": \"air\", \"hasContext\": \"daily maximum air temperature\", \"ContextURI\": \"http://purl.obolibrary.org/obo/ECOSIM_TAMX\"}\n",
      "LLM Output: {\"Variable\": \"Air daily maximum temperature\", \"hasObjectOfInterest\": \"air\", \"objectOfInterestURI\": \"http://vocabs.lter-europe.net/EnvThes/30364\", \"hasProperty\": \"temperature\", \"hasPropertyURI\": \"https://qudt.org/vocab/quantitykind/Temperature\", \"hasMatrix\": \"atmosphere\", \"MatrixURI\": \"http://purl.obolibrary.org/obo/ENVO_01000252\", \"hasConstraint\": \"height\", \"ConstraintURI\": \"http://purl.obolibrary.org/obo/ENVO_01001402\", \"constrain1\": \"1.7 meter\", \"hasContext\": \"daily maximum\", \"ContextURI\": \"http://purl.obolibrary.org/obo/NCIT_C64564\"}\n",
      "--------------------------------------------------\n",
      "File: var17.json\n",
      "Model: gpt-4o-mini\n",
      "Variable: Docosahexaenoic acid content per dry weight (DHA content/ C22:6 n-3 content)\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"docosahexaenoic acid\", \"objectOfInterestURI\": \"http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#C68345\", \"hasProperty\": \"relative dry weight\", \"hasPropertyURI\": \"http://purl.obolibrary.org/obo/TO_0000633\", \"hasMatrix\": \"individual\", \"MatrixURI\": \"http://www.ebi.ac.uk/efo/EFO_0000542\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": null, \"ContextURI\": null}\n",
      "LLM Output: {\"Variable\": \"Docosahexaenoic acid content per dry weight (DHA content/ C22:6 n-3 content)\", \"hasObjectOfInterest\": \"individual\", \"objectOfInterestURI\": \"http://example.org/ontology/individual\", \"hasProperty\": \"content\", \"hasPropertyURI\": \"http://example.org/ontology/content\", \"hasMatrix\": \"dry weight\", \"MatrixURI\": \"http://example.org/ontology/dry_weight\", \"hasConstraint\": \"relative measurement\", \"ConstraintURI\": \"http://example.org/ontology/relative_measurement\", \"constrain1\": \"DHA content must be expressed as a proportion of dry weight\", \"hasContext\": \"nutritional analysis\", \"ContextURI\": \"http://example.org/ontology/nutritional_analysis\"}\n",
      "--------------------------------------------------\n",
      "File: var17.json\n",
      "Model: gpt-4o\n",
      "Variable: Docosahexaenoic acid content per dry weight (DHA content/ C22:6 n-3 content)\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"docosahexaenoic acid\", \"objectOfInterestURI\": \"http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#C68345\", \"hasProperty\": \"relative dry weight\", \"hasPropertyURI\": \"http://purl.obolibrary.org/obo/TO_0000633\", \"hasMatrix\": \"individual\", \"MatrixURI\": \"http://www.ebi.ac.uk/efo/EFO_0000542\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": null, \"ContextURI\": null}\n",
      "LLM Output: {\"Variable\": \"Docosahexaenoic acid content per dry weight (DHA content/ C22:6 n-3 content)\", \"hasObjectOfInterest\": \"docosahexaenoic acid\", \"objectOfInterestURI\": \"\", \"hasProperty\": \"content\", \"hasPropertyURI\": \"\", \"hasMatrix\": \"dry weight\", \"MatrixURI\": \"\", \"hasConstraint\": \"\", \"ConstraintURI\": \"\", \"constrain1\": \"\", \"hasContext\": \"individual\", \"ContextURI\": \"\"}\n",
      "--------------------------------------------------\n",
      "File: var5.json\n",
      "Model: gpt-4o-mini\n",
      "Variable: Atmosphere_optical_thickness_due_to_particulate_organic_matter_ambient_aerosol\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"Aerosol\", \"objectOfInterestURI\": \"http://purl.bioontology.org/ontology/SNOMEDCT/64242006\", \"hasProperty\": \"Optical Thickness\", \"hasPropertyURI\": \"http://sweetontology.net/propSpaceThickness/OpticalThickness\", \"hasMatrix\": \"Atmosphere\", \"MatrixURI\": \"http://purl.bioontology.org/ontology/SNOMEDCT/304607008\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": \"Path of Radiation\", \"ContextURI\": \"http://www.example.org/path_of_radition\"}\n",
      "LLM Output: {\"Variable\": \"Atmosphere_optical_thickness_due_to_particulate_organic_matter_ambient_aerosol\", \"hasObjectOfInterest\": \"atmosphere\", \"objectOfInterestURI\": \"http://vocabs.lter-europe.net/EnvThes/30366\", \"hasProperty\": \"optical thickness\", \"hasPropertyURI\": \"https://qudt.org/vocab/quantitykind/OpticalThickness\", \"hasMatrix\": \"ambient aerosol\", \"MatrixURI\": \"http://purl.obolibrary.org/obo/RBO_00000018\", \"hasConstraint\": \"none\", \"ConstraintURI\": \"none\", \"constrain1\": \"none\", \"hasContext\": \"none\", \"ContextURI\": \"none\"}\n",
      "--------------------------------------------------\n",
      "File: var5.json\n",
      "Model: gpt-4o\n",
      "Variable: Atmosphere_optical_thickness_due_to_particulate_organic_matter_ambient_aerosol\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"Aerosol\", \"objectOfInterestURI\": \"http://purl.bioontology.org/ontology/SNOMEDCT/64242006\", \"hasProperty\": \"Optical Thickness\", \"hasPropertyURI\": \"http://sweetontology.net/propSpaceThickness/OpticalThickness\", \"hasMatrix\": \"Atmosphere\", \"MatrixURI\": \"http://purl.bioontology.org/ontology/SNOMEDCT/304607008\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": \"Path of Radiation\", \"ContextURI\": \"http://www.example.org/path_of_radition\"}\n",
      "LLM Output: {\"Variable\": \"Atmosphere_optical_thickness_due_to_particulate_organic_matter_ambient_aerosol\", \"hasObjectOfInterest\": \"particulate organic matter\", \"objectOfInterestURI\": \"\", \"hasProperty\": \"optical thickness\", \"hasPropertyURI\": \"\", \"hasMatrix\": \"ambient aerosol\", \"MatrixURI\": \"\", \"hasConstraint\": \"\", \"ConstraintURI\": \"\", \"constrain1\": \"\", \"hasContext\": \"atmosphere\", \"ContextURI\": \"\"}\n",
      "--------------------------------------------------\n",
      "File: var4.json\n",
      "Model: gpt-4o-mini\n",
      "Variable: Atmospheric boundary layer heights\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"valley floor\", \"objectOfInterestURI\": \"https://example.org/valley_floor\", \"hasProperty\": \"height-range\", \"hasPropertyURI\": \"http://sweetontology.net/propSpaceHeight/HeightRange\", \"hasMatrix\": \"Boundary Layer/Free Troposphere\", \"MatrixURI\": \"http://sweetontology.net/realmAtmo/FreeTroposphere\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": null, \"ContextURI\": null}\n",
      "LLM Output: {\"Variable\": \"Atmospheric boundary layer heights\", \"hasObjectOfInterest\": \"boundary layer air/free troposphere\", \"objectOfInterestURI\": \"http://example.org/atmospheric-boundary-layer\", \"hasProperty\": \"height-range\", \"hasPropertyURI\": \"https://qudt.org/vocab/quantitykind/Height\", \"hasMatrix\": \"valley floor\", \"MatrixURI\": \"http://example.org/valley-floor\", \"hasConstraint\": \"influenced by\", \"ConstraintURI\": \"http://example.org/constraints/influence\", \"constrain1\": \"boundary layer air\", \"hasContext\": \"atmospheric conditions\", \"ContextURI\": \"http://example.org/context/atmospheric-conditions\"}\n",
      "--------------------------------------------------\n",
      "File: var4.json\n",
      "Model: gpt-4o\n",
      "Variable: Atmospheric boundary layer heights\n",
      "Ground Truth: {\"hasObjectOfInterest\": \"valley floor\", \"objectOfInterestURI\": \"https://example.org/valley_floor\", \"hasProperty\": \"height-range\", \"hasPropertyURI\": \"http://sweetontology.net/propSpaceHeight/HeightRange\", \"hasMatrix\": \"Boundary Layer/Free Troposphere\", \"MatrixURI\": \"http://sweetontology.net/realmAtmo/FreeTroposphere\", \"hasConstraint\": null, \"ConstraintURI\": null, \"constrain1\": null, \"hasContext\": null, \"ContextURI\": null}\n",
      "LLM Output: {\"Variable\": \"Atmospheric boundary layer heights\", \"hasObjectOfInterest\": \"boundary layer air\", \"objectOfInterestURI\": \"\", \"hasProperty\": \"height\", \"hasPropertyURI\": \"https://qudt.org/vocab/quantitykind/Height\", \"hasMatrix\": \"valley floor\", \"MatrixURI\": \"\", \"hasConstraint\": \"\", \"ConstraintURI\": \"\", \"constrain1\": \"\", \"hasContext\": \"free troposphere\", \"ContextURI\": \"\"}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 10) Finally, show ground truth and LLM outputs after the summary\n",
    "print(\"\\n=== Ground Truth vs. LLM Output Details ===\\n\")\n",
    "for idx, row in df_results.iterrows():\n",
    "    print(\"File:\", row[\"File\"])\n",
    "    print(\"Model:\", row[\"Model\"])\n",
    "    print(\"Variable:\", row[\"Variable\"])\n",
    "    print(\"Ground Truth:\", row[\"GroundTruth\"])\n",
    "    print(\"LLM Output:\", row[\"LLMOutput\"])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93ed6fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"Variable\": \"Atmospheric boundary layer heights\",\\n  \"hasObjectOfInterest\": \"boundary layer air\",\\n  \"objectOfInterestURI\": \"\",\\n  \"hasProperty\": \"height\",\\n  \"hasPropertyURI\": \"https://qudt.org/vocab/quantitykind/Height\",\\n  \"hasMatrix\": \"valley floor\",\\n  \"MatrixURI\": \"\",\\n  \"hasConstraint\": \"\",\\n  \"ConstraintURI\": \"\",\\n  \"constrain1\": \"\",\\n  \"hasContext\": \"free troposphere\",\\n  \"ContextURI\": \"\"\\n}\\n```'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1933c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
