{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8cf496",
   "metadata": {},
   "source": [
    "Implementing evaluation mertics on a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c71fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai\n",
    "# !pip install langchain\n",
    "# !pip install pandas\n",
    "# !pip install -U sentence-transformers\n",
    "# !pip install rapidfuzz\n",
    "# !pip install openpyxl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b8f0fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import re\n",
    "from rapidfuzz import fuzz \n",
    "from datetime import datetime\n",
    "import pathlib\n",
    "import openpyxl  \n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84703d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Load from .env file in current directory\n",
    "load_dotenv()\n",
    "\n",
    "# Get the token from the environment\n",
    "hf_token = os.getenv(\"hugging_face_api_key\")\n",
    "\n",
    "# Optional: check if token is loaded\n",
    "if not hf_token:\n",
    "    raise ValueError(\"HUGGINGFACE_HUB_TOKEN not found in .env\")\n",
    "\n",
    "# Login to Hugging Face Hub\n",
    "login(token=hf_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a469c",
   "metadata": {},
   "source": [
    "Variable 1, 4 and 10 are given as examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3b98103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Prompt template for asking the model to decompose the variable\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are a knowledge engineer and a climate change scientist. I need you to model a climate change variable using the I-ADOPT framework. A variable is usually the result of a sensor measurement or of a laboratory analysis on a sample. The task is to generate Json code with a description of the variable according to the I-ADOPT ontology. See the following examples: \n",
    "Example 1:\n",
    "{{\n",
    "  \"Provided Variable Name\": \"Electron density in the solar wind\",\n",
    "  \"Definition\": \"Density (particle per cm3) of electrons measured in the Solar Wind.\",\n",
    "  \"Property (Label)\": \"volumetric number density\",\n",
    "  \"ObjectOfInterest (Label)\": \"electron\",\n",
    "  \"Matrix (Label)\": \"solar wind\",\n",
    "  \"Applicable units of measure\": \"cm-3\"\n",
    "}}\n",
    "Example 2:\n",
    "{{\n",
    "  \"Provided Variable Name\": \"Atmospheric boundary layer height defined by temperature inversion\",\n",
    "  \"Definition\": \"Atmospheric boundary layer height defined by temperature inversion.\",\n",
    "  \"Property (Label)\": \"height\",\n",
    "  \"ObjectOfInterest (Label)\": \"atmospheric boundary layer\",\n",
    "  \"Matrix (Label)\": \"atmosphere\",\n",
    "  \"constraint\": [\n",
    "    \"defined by temperature inversion\",\n",
    "    \"above the valley floor\"\n",
    "  ],\n",
    "  \"Constraint component\": [\n",
    "    \"atmospheric boundary layer\",\n",
    "    \"height\"\n",
    "  ],\n",
    "  \"Applicable units of measure\": \"m\"\n",
    "}}\n",
    "Example 3:\n",
    "{{\n",
    "  \"Provided Variable Name\": \"Peak ground acceleration\",\n",
    "  \"Definition\": \"Peak acceleration measured on the earth surface when facing seismic events, like earthquakes.\",\n",
    "  \"Statistical Modifier\": \"maximum\",\n",
    "  \"Property (Label)\": \"acceleration\",\n",
    "  \"ObjectOfInterest (Label)\": \"ground\",\n",
    "  \"constraint\": [\n",
    "    \"surface\",\n",
    "    \"during seismic events\"\n",
    "  ],\n",
    "  \"Constraint component\": [\n",
    "    \"ground\",\n",
    "    \"acceleration\"\n",
    "  ],\n",
    "  \"Applicable units of measure\": \"m s-2\"\n",
    "}}\n",
    "Given the example above. model the following variable:\n",
    "Variable: {variable}\n",
    "Description: {description}\n",
    "Decompose it into:\n",
    "- Statistical Modifier (Label) --OPTIONAL--\n",
    "- Property (Label)\n",
    "- ObjectOfInterest (Label)\n",
    "- Matrix (Label) --OPTIONAL--\n",
    "- ContextObject (Label) --OPTIONAL--\n",
    "- constraint --OPTIONAL--\n",
    "- Constraint component --OPTIONAL--\n",
    "- Applicable units of measure --OPTIONAL--\n",
    "Return a JSON in this exact format:\n",
    "{{\n",
    "  \"Provided Variable Name\": \"...\",\n",
    "  \"Definition\": \"...\",\n",
    "  \"Statistical Modifier (Label)\": \"...\",\n",
    "  \"Property (Label)\": \"...\", \n",
    "  \"ObjectOfInterest (Label)\": \"...\",\n",
    "  \"Matrix (Label)\": \"...\",\n",
    "  \"ContextObject (Label)\": \"...\",\n",
    "  \"constraint\": \"...\"\n",
    "  \"Constraint component\": \"...\",\n",
    "  \"Applicable units of measure\": \"...\"\n",
    "}}\n",
    "\"\"\",\n",
    "    input_variables=[\"variable\", \"description\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbfff24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_from_response(response_text):\n",
    "    \"\"\"\n",
    "    Extract the first valid JSON object from the response text.\n",
    "    Cleans up common formatting like ```json or plain ``` fences.\n",
    "    \"\"\"\n",
    "    # Remove code block markers like ```json or ```\n",
    "    cleaned_text = re.sub(r\"```(?:json)?\", \"\", response_text).strip()\n",
    "\n",
    "    # Attempt to extract a JSON-like structure using regex\n",
    "    match = re.search(r\"\\{.*\\}\", cleaned_text, re.DOTALL)\n",
    "    if match:\n",
    "        json_str = match.group(0)\n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"JSON decoding failed:\", e)\n",
    "            return {}\n",
    "    else:\n",
    "        print(\"No JSON found in response.\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07989f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Folder containing JSON files (each file has one ground-truth variable record)\n",
    "json_folder = \"/Users/rastegar-a/Documents/GitHub/i-adopt-llm-based-service/benchmarking_example/data/\"\n",
    "json_folder = \"/Users/rastegar-a/Documents/GitHub/i-adopt-llm-based-service/benchmarking_example/data/five_variables/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce33a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Models you want to compare on OpenRouter or OpenAI\n",
    "# model_names = [\"deepseek/deepseek-v3-base:free\", \"google/gemini-2.5-pro-exp-03-25:free\"] # OpenRouter models\n",
    "# model_names = [\"deepseek/deepseek-v3-base:free\"] # OpenRouter models\n",
    "####### ----\n",
    "model_names = [\n",
    "    \"mistralai/mistral-7b-instruct\",\n",
    "    \"mistralai/mistral-small-24b-instruct-2501\",\n",
    "    \"meta-llama/llama-3.2-11b-vision-instruct\",\n",
    "    \"meta-llama/llama-3.3-70b-instruct\",\n",
    "    \"openai/gpt-4o-mini\",\n",
    "    \"openai/gpt-4.1-mini\"\n",
    "]\n",
    "### Initialize OpenRouter client (replace <OPENROUTER_API_KEY> with your actual API key).\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),    \n",
    ")\n",
    "\n",
    "############ -----\n",
    "# model_names = [\"gpt-4o-mini\", \"gpt-4o\"]\n",
    "# client = OpenAI(\n",
    "#     api_key=os.getenv(\"OPENAI_API_KEY\"),    \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8305a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) LLM call helper using OpenRouter's chat endpoint\n",
    "def call_model_openrouter(model_name, user_prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        extra_headers={\n",
    "            \"HTTP-Referer\": \"<YOUR_SITE_URL>\",  # optional\n",
    "            \"X-Title\": \"<YOUR_SITE_NAME>\"       # optional\n",
    "        },\n",
    "        model=model_name,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    # print(f\"Model: {model_name}, Response: {response}\")\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 6) Embedding model (SentenceTransformer) for checking similarity\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def embedding_similarity(text1, text2):\n",
    "    \"\"\"Compute cosine similarity between two pieces of text.\"\"\"\n",
    "    emb1 = embed_model.encode(text1, convert_to_tensor=True)\n",
    "    emb2 = embed_model.encode(text2, convert_to_tensor=True)\n",
    "    return util.cos_sim(emb1, emb2).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60de5874",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXACT_THRESHOLD = 0.90          # tweak if you want it stricter/looser\n",
    "\n",
    "def exact_similarity(s1: str, s2: str) -> float:\n",
    "    \"\"\"CaseInsensitive Levenshtein ratio in [0,1].\"\"\"\n",
    "    return fuzz.ratio(s1.lower().strip(), s2.lower().strip()) / 100.0\n",
    "\n",
    "\n",
    "def compute_confusion_for_field_exact(gt_val, pred_val, threshold=EXACT_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Same logic as your embed version, but uses exact_similarity.\n",
    "    \"\"\"\n",
    "    # list → comma‑separated str\n",
    "    if isinstance(gt_val, list):\n",
    "        gt_val = \", \".join(str(v).strip() for v in gt_val if v)\n",
    "    if isinstance(pred_val, list):\n",
    "        pred_val = \", \".join(str(v).strip() for v in pred_val if v)\n",
    "\n",
    "    gt_val  = gt_val.strip()  if isinstance(gt_val,  str) else \"\"\n",
    "    pred_val = pred_val.strip() if isinstance(pred_val, str) else \"\"\n",
    "\n",
    "    if gt_val:                                          # ground‑truth present\n",
    "        if pred_val:                                    # prediction present\n",
    "            sim = exact_similarity(gt_val, pred_val)\n",
    "            return (1,0,0,0) if sim >= threshold else (0,0,1,0)   # TP or FN\n",
    "        else:\n",
    "            return (0,0,1,0)                            # FN\n",
    "    else:                                               # ground‑truth absent\n",
    "        return (0,1,0,0) if pred_val else (0,0,0,1)     # FP or TN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e2962d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) We'll evaluate each of these keys with a threshold for correctness\n",
    "# ONTO_KEYS = [\"hasObjectOfInterest\", \"hasProperty\", \"hasMatrix\", \"hasConstraint\", \"constrain1\", \"hasContext\"]\n",
    "ONTO_KEYS =  [\"Statistical Modifier (Label)\", \"Property (Label)\", \"ObjectOfInterest (Label)\", \"Matrix (Label)\", \"ContextObject (Label)\", \"constraint\", \"Constraint component\", \"Applicable units of measure\"]\n",
    "THRESHOLD = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56c88468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion_for_field(gt_val, pred_val, threshold=0.90):\n",
    "    \"\"\"\n",
    "    Correct Logic:\n",
    "      True Positive (TP):   GT not empty, pred not empty, similarity >= threshold\n",
    "      False Positive (FP):  GT empty, pred not empty\n",
    "      False Negative (FN):  GT not empty and (pred empty OR similarity < threshold)\n",
    "      True Negative (TN):   GT empty, pred empty\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert lists to string representations\n",
    "    if isinstance(gt_val, list):\n",
    "        gt_val = \", \".join(str(v).strip() for v in gt_val if v)\n",
    "    if isinstance(pred_val, list):\n",
    "        pred_val = \", \".join(str(v).strip() for v in pred_val if v)\n",
    "\n",
    "    # Strip leading/trailing whitespace\n",
    "    gt_val = gt_val.strip() if isinstance(gt_val, str) else \"\"\n",
    "    pred_val = pred_val.strip() if isinstance(pred_val, str) else \"\"\n",
    "\n",
    "    # If ground truth is non-empty => label is \"present\".\n",
    "    if gt_val:\n",
    "        # Prediction non-empty => check similarity\n",
    "        if pred_val:\n",
    "            sim = embedding_similarity(gt_val, pred_val)\n",
    "            if sim >= threshold:\n",
    "                return (1, 0, 0, 0)  # TP\n",
    "            else:\n",
    "                return (0, 0, 1, 0)  # FN (prediction too dissimilar)\n",
    "        else:\n",
    "            # Prediction empty => definitely FN\n",
    "            return (0, 0, 1, 0)\n",
    "    \n",
    "    # If ground truth is empty => label is \"absent\".\n",
    "    else:\n",
    "        if pred_val:\n",
    "            # Predicted something when nothing was needed => FP\n",
    "            return (0, 1, 0, 0)\n",
    "        else:\n",
    "            # Both empty => TN\n",
    "            return (0, 0, 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "# Helper to compute precision, recall, f1 from confusion matrix totals\n",
    "def precision_recall_f1(tp, fp, fn, tn):\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    if precision + recall == 0:\n",
    "        f1 = 0.0\n",
    "    else:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfd97d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON decoding failed: Extra data: line 19 column 1 (char 628)\n"
     ]
    }
   ],
   "source": [
    "# 8) Main loop over JSON files\n",
    "all_rows = []  # We'll store row-based results to build a DF\n",
    "\n",
    "for file_name in os.listdir(json_folder):\n",
    "    if file_name.endswith(\".json\"):\n",
    "        with open(os.path.join(json_folder, file_name), \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Failed to parse {file_name}: {e}\")\n",
    "                continue\n",
    "\n",
    "            variable_text = data.get(\"Provided Variable Name\", \"\")\n",
    "            description_text = data.get(\"Definition\", \"\")\n",
    "            ground_truth = {k: data.get(k, \"\") for k in ONTO_KEYS}\n",
    "            prompt_text = prompt_template.format(\n",
    "                variable=variable_text,\n",
    "                description=description_text\n",
    "            )\n",
    "\n",
    "            # For each model, get predictions and compute confusion matrix\n",
    "            for model_name in model_names:\n",
    "                llm_output = call_model_openrouter(model_name, prompt_text)\n",
    "                # --- Remove code fences if present ---\n",
    "                # This will remove any ``` or ```json lines\n",
    "                # cleaned_output = re.sub(r\"```(\\w+)?\", \"\", llm_output).strip()\n",
    "\n",
    "                # Attempt to parse the cleaned string as JSON\n",
    "                predicted_json = extract_json_from_response(llm_output)\n",
    "\n",
    "                # Accumulate confusion counts across all keys\n",
    "                total_tp_embed = total_fp_embed = total_fn_embed = total_tn_embed = 0\n",
    "                total_tp_exact = total_fp_exact = total_fn_exact = total_tn_exact = 0   \n",
    "                for key in ONTO_KEYS:\n",
    "                    gt_val = ground_truth.get(key, \"\") or \"\"\n",
    "                    pred_val = predicted_json.get(key, \"\") or \"\"\n",
    "                    # print(f\"GT: {gt_val}, Pred: {pred_val}\")\n",
    "                    # --- Embedding version ---\n",
    "                    tp_e, fp_e, fn_e, tn_e = compute_confusion_for_field(gt_val, pred_val)\n",
    "                    total_tp_embed += tp_e\n",
    "                    total_fp_embed += fp_e\n",
    "                    total_fn_embed += fn_e\n",
    "                    total_tn_embed += tn_e\n",
    "\n",
    "                    # --- Exact‑match version ---\n",
    "                    tp_x, fp_x, fn_x, tn_x = compute_confusion_for_field_exact(gt_val, pred_val)\n",
    "                    total_tp_exact += tp_x\n",
    "                    total_fp_exact += fp_x\n",
    "                    total_fn_exact += fn_x\n",
    "                    total_tn_exact += tn_x\n",
    "\n",
    "                prec_embed, rec_embed, f1_embed = precision_recall_f1(total_tp_embed, total_fp_embed, total_fn_embed, total_tn_embed)\n",
    "                prec_exact, rec_exact, f1_exact = precision_recall_f1(total_tp_exact, total_fp_exact, total_fn_exact, total_tn_exact)\n",
    "                filtered_output = {k: v for k, v in predicted_json.items() if k not in [\"Provided Variable Name\", \"Definition\"]}\n",
    "                # Store everything in all_rows, including ground truth & the predicted JSON\n",
    "                row_dict = {\n",
    "                \"File\": file_name,\n",
    "                \"Variable\": variable_text,\n",
    "                \"Model\": model_name,\n",
    "\n",
    "                # --- embedding metrics ---\n",
    "                \"TP_embed\": total_tp_embed, \"FP_embed\": total_fp_embed,\n",
    "                \"FN_embed\": total_fn_embed, \"TN_embed\": total_tn_embed,\n",
    "                \"Precision_embed\": round(prec_embed, 3),\n",
    "                \"Recall_embed\":    round(rec_embed, 3),\n",
    "                \"F1_embed\":        round(f1_embed, 3),\n",
    "\n",
    "                # --- exact‑match metrics ---\n",
    "                \"TP_exact\": total_tp_exact, \"FP_exact\": total_fp_exact,\n",
    "                \"FN_exact\": total_fn_exact, \"TN_exact\": total_tn_exact,\n",
    "                \"Precision_exact\": round(prec_exact, 3),\n",
    "                \"Recall_exact\":    round(rec_exact, 3),\n",
    "                \"F1_exact\":        round(f1_exact, 3),\n",
    "\n",
    "                # diagnostic text\n",
    "                \"GroundTruth\": json.dumps(ground_truth),\n",
    "                \"LLMOutput\":   json.dumps(filtered_output)\n",
    "                }\n",
    "                all_rows.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f00dfa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PerModel Averages EMBEDDING SIMILARITY ===\n",
      "                                       Model  Precision_embed  Recall_embed  \\\n",
      "1   meta-llama/llama-3.2-11b-vision-instruct            0.353         0.263   \n",
      "4  mistralai/mistral-small-24b-instruct-2501            0.310         0.257   \n",
      "5                        openai/gpt-4.1-mini            0.337         0.223   \n",
      "0      deepseek/deepseek-r1-distill-qwen-14b            0.327         0.223   \n",
      "3              mistralai/mistral-7b-instruct            0.277         0.223   \n",
      "6                         openai/gpt-4o-mini            0.440         0.190   \n",
      "2          meta-llama/llama-3.3-70b-instruct            0.240         0.230   \n",
      "\n",
      "   F1_embed  \n",
      "1     0.293  \n",
      "4     0.278  \n",
      "5     0.259  \n",
      "0     0.253  \n",
      "3     0.242  \n",
      "6     0.240  \n",
      "2     0.233  \n",
      "\n",
      "=== PerModel Averages EXACT MATCH (case/typoInsensitive) ===\n",
      "                                       Model  Precision_exact  Recall_exact  \\\n",
      "4  mistralai/mistral-small-24b-instruct-2501            0.310         0.257   \n",
      "5                        openai/gpt-4.1-mini            0.337         0.223   \n",
      "1   meta-llama/llama-3.2-11b-vision-instruct            0.320         0.230   \n",
      "0      deepseek/deepseek-r1-distill-qwen-14b            0.327         0.223   \n",
      "3              mistralai/mistral-7b-instruct            0.277         0.223   \n",
      "6                         openai/gpt-4o-mini            0.440         0.190   \n",
      "2          meta-llama/llama-3.3-70b-instruct            0.240         0.230   \n",
      "\n",
      "   F1_exact  \n",
      "4     0.278  \n",
      "5     0.259  \n",
      "1     0.258  \n",
      "0     0.253  \n",
      "3     0.242  \n",
      "6     0.240  \n",
      "2     0.233  \n"
     ]
    }
   ],
   "source": [
    "# 9) Create a DataFrame with aggregated results\n",
    "df_results = pd.DataFrame(all_rows)\n",
    "# print(\"\\n=== Final Results DataFrame ===\\n\")\n",
    "# print(df_results)\n",
    "\n",
    "# 10) Compute average metrics for each model (across all files)\n",
    "# Embedding\n",
    "summary_embed = df_results.groupby([\"Model\"]).agg({\n",
    "    \"Precision_embed\":\"mean\",\n",
    "    \"Recall_embed\":\"mean\",\n",
    "    \"F1_embed\":\"mean\"\n",
    "}).reset_index().round(3).sort_values(\"F1_embed\", ascending=False)\n",
    "\n",
    "# Exact match\n",
    "summary_exact = df_results.groupby([\"Model\"]).agg({\n",
    "    \"Precision_exact\":\"mean\",\n",
    "    \"Recall_exact\":\"mean\",\n",
    "    \"F1_exact\":\"mean\"\n",
    "}).reset_index().round(3).sort_values(\"F1_exact\", ascending=False)\n",
    "\n",
    "print(\"\\n=== PerModel Averages EMBEDDING SIMILARITY ===\")\n",
    "print(summary_embed)\n",
    "\n",
    "print(\"\\n=== PerModel Averages EXACT MATCH (case/typoInsensitive) ===\")\n",
    "print(summary_exact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d9a186b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ground Truth vs. LLM Output Details ===\n",
      "\n",
      "File: variable_21.0.json\n",
      "Model: mistralai/mistral-7b-instruct\n",
      "Variable: Resting systolic blood pressure\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"pressure\", \"ObjectOfInterest (Label)\": \"blood\", \"Matrix (Label)\": \"human\", \"ContextObject (Label)\": \"\", \"constraint\": [\"systolic\", \"resting\"], \"Constraint component\": [\"pressure\", \"human\"], \"Applicable units of measure\": \"\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"systolic\", \"Property (Label)\": \"blood pressure\", \"ObjectOfInterest (Label)\": \"blood\", \"Matrix (Label)\": \"body\", \"ContextObject (Label)\": \"resting\", \"constraint\": [\"during rest\"], \"Constraint component\": [\"blood pressure\", \"systolic\"], \"Applicable units of measure\": \"mmHg\"}\n",
      "--------------------------------------------------\n",
      "File: variable_21.0.json\n",
      "Model: mistralai/mistral-small-24b-instruct-2501\n",
      "Variable: Resting systolic blood pressure\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"pressure\", \"ObjectOfInterest (Label)\": \"blood\", \"Matrix (Label)\": \"human\", \"ContextObject (Label)\": \"\", \"constraint\": [\"systolic\", \"resting\"], \"Constraint component\": [\"pressure\", \"human\"], \"Applicable units of measure\": \"\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"resting\", \"Property (Label)\": \"systolic blood pressure\", \"ObjectOfInterest (Label)\": \"blood\", \"Matrix (Label)\": \"circulatory system\", \"ContextObject (Label)\": \"human body\", \"constraint\": [\"measured during rest\"], \"Constraint component\": [\"blood\", \"systolic pressure\"], \"Applicable units of measure\": \"mmHg\"}\n",
      "--------------------------------------------------\n",
      "File: variable_21.0.json\n",
      "Model: meta-llama/llama-3.2-11b-vision-instruct\n",
      "Variable: Resting systolic blood pressure\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"pressure\", \"ObjectOfInterest (Label)\": \"blood\", \"Matrix (Label)\": \"human\", \"ContextObject (Label)\": \"\", \"constraint\": [\"systolic\", \"resting\"], \"Constraint component\": [\"pressure\", \"human\"], \"Applicable units of measure\": \"\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"average\", \"Property (Label)\": \"pressure\", \"ObjectOfInterest (Label)\": \"blood\", \"Matrix (Label)\": \"arterial\", \"ContextObject (Label)\": \"resting\", \"constraint\": [\"systolic\", \"diastolic\"], \"Constraint component\": [\"blood\", \"pressure\"], \"Applicable units of measure\": \"mmHg\"}\n",
      "--------------------------------------------------\n",
      "File: variable_21.0.json\n",
      "Model: meta-llama/llama-3.3-70b-instruct\n",
      "Variable: Resting systolic blood pressure\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"pressure\", \"ObjectOfInterest (Label)\": \"blood\", \"Matrix (Label)\": \"human\", \"ContextObject (Label)\": \"\", \"constraint\": [\"systolic\", \"resting\"], \"Constraint component\": [\"pressure\", \"human\"], \"Applicable units of measure\": \"\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"None\", \"Property (Label)\": \"pressure\", \"ObjectOfInterest (Label)\": \"blood\", \"Matrix (Label)\": \"vascular system\", \"ContextObject (Label)\": \"human body\", \"constraint\": \"at rest\", \"Constraint component\": \"systolic phase\", \"Applicable units of measure\": \"mmHg\"}\n",
      "--------------------------------------------------\n",
      "File: variable_21.0.json\n",
      "Model: deepseek/deepseek-r1-distill-qwen-14b\n",
      "Variable: Resting systolic blood pressure\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"pressure\", \"ObjectOfInterest (Label)\": \"blood\", \"Matrix (Label)\": \"human\", \"ContextObject (Label)\": \"\", \"constraint\": [\"systolic\", \"resting\"], \"Constraint component\": [\"pressure\", \"human\"], \"Applicable units of measure\": \"\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"pressure\", \"ObjectOfInterest (Label)\": \"artery\", \"Matrix (Label)\": \"blood\", \"ContextObject (Label)\": \"body\", \"constraint\": [\"at rest\"], \"Constraint component\": [\"person\", \"resting state\"], \"Applicable units of measure\": \"mmHg\"}\n",
      "--------------------------------------------------\n",
      "File: variable_21.0.json\n",
      "Model: openai/gpt-4o-mini\n",
      "Variable: Resting systolic blood pressure\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"pressure\", \"ObjectOfInterest (Label)\": \"blood\", \"Matrix (Label)\": \"human\", \"ContextObject (Label)\": \"\", \"constraint\": [\"systolic\", \"resting\"], \"Constraint component\": [\"pressure\", \"human\"], \"Applicable units of measure\": \"\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"resting\", \"Property (Label)\": \"blood pressure\", \"ObjectOfInterest (Label)\": \"blood\", \"Applicable units of measure\": \"mmHg\"}\n",
      "--------------------------------------------------\n",
      "File: variable_21.0.json\n",
      "Model: openai/gpt-4.1-mini\n",
      "Variable: Resting systolic blood pressure\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"pressure\", \"ObjectOfInterest (Label)\": \"blood\", \"Matrix (Label)\": \"human\", \"ContextObject (Label)\": \"\", \"constraint\": [\"systolic\", \"resting\"], \"Constraint component\": [\"pressure\", \"human\"], \"Applicable units of measure\": \"\"}\n",
      "LLM Output: {\"Property (Label)\": \"blood pressure systolic\", \"ObjectOfInterest (Label)\": \"blood\", \"ContextObject (Label)\": \"resting state\", \"Applicable units of measure\": \"mmHg\"}\n",
      "--------------------------------------------------\n",
      "File: variable_8.0.json\n",
      "Model: mistralai/mistral-7b-instruct\n",
      "Variable: Coarse woody debris abundance\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"coarse woody debris\", \"Matrix (Label)\": \"ground\", \"ContextObject (Label)\": \"\", \"constraint\": \"\", \"Constraint component\": \"\", \"Applicable units of measure\": \"m2 ha-1\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"per hectare\", \"Property (Label)\": \"abundance\", \"ObjectOfInterest (Label)\": \"Coarse Woody Debris\", \"Matrix (Label)\": \"Forest\", \"ContextObject (Label)\": \"Plots/Transects\", \"constraint\": \"measured using the formula (see https://www.sciencedirect.com/science/article/pii/S037811270900783X)\", \"Constraint component\": [\"Coarse Woody Debris\", \"abundance\"], \"Applicable units of measure\": \"m2/hectare\"}\n",
      "--------------------------------------------------\n",
      "File: variable_8.0.json\n",
      "Model: mistralai/mistral-small-24b-instruct-2501\n",
      "Variable: Coarse woody debris abundance\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"coarse woody debris\", \"Matrix (Label)\": \"ground\", \"ContextObject (Label)\": \"\", \"constraint\": \"\", \"Constraint component\": \"\", \"Applicable units of measure\": \"m2 ha-1\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"abundance\", \"Property (Label)\": \"abundance\", \"ObjectOfInterest (Label)\": \"coarse woody debris\", \"Matrix (Label)\": \"forest\", \"ContextObject (Label)\": \"plot/transect\", \"constraint\": [\"measured from all the plots/transects\", \"scaled to a hectare (100 x 100 m)\"], \"Constraint component\": [\"coarse woody debris\", \"abundance\"], \"Applicable units of measure\": \"m2/hectare\"}\n",
      "--------------------------------------------------\n",
      "File: variable_8.0.json\n",
      "Model: meta-llama/llama-3.2-11b-vision-instruct\n",
      "Variable: Coarse woody debris abundance\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"coarse woody debris\", \"Matrix (Label)\": \"ground\", \"ContextObject (Label)\": \"\", \"constraint\": \"\", \"Constraint component\": \"\", \"Applicable units of measure\": \"m2 ha-1\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"total\", \"Property (Label)\": \"abundance\", \"ObjectOfInterest (Label)\": \"coarse woody debris\", \"Matrix (Label)\": \"plots/transects\", \"ContextObject (Label)\": \"hectare\", \"constraint\": [\"measured from all the plots/transects\", \"scaled to a hectare (100 x 100 m)\"], \"Constraint component\": [\"coarse woody debris\", \"abundance\"], \"Applicable units of measure\": \"m2/hectare\"}\n",
      "--------------------------------------------------\n",
      "File: variable_8.0.json\n",
      "Model: meta-llama/llama-3.3-70b-instruct\n",
      "Variable: Coarse woody debris abundance\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"coarse woody debris\", \"Matrix (Label)\": \"ground\", \"ContextObject (Label)\": \"\", \"constraint\": \"\", \"Constraint component\": \"\", \"Applicable units of measure\": \"m2 ha-1\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"none\", \"Property (Label)\": \"abundance\", \"ObjectOfInterest (Label)\": \"coarse woody debris\", \"Matrix (Label)\": \"forest/terrestrial ecosystem\", \"ContextObject (Label)\": \"plots/transects\", \"constraint\": \"per hectare\", \"Constraint component\": \"coarse woody debris abundance\", \"Applicable units of measure\": \"m2/hectare\"}\n",
      "--------------------------------------------------\n",
      "File: variable_8.0.json\n",
      "Model: deepseek/deepseek-r1-distill-qwen-14b\n",
      "Variable: Coarse woody debris abundance\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"coarse woody debris\", \"Matrix (Label)\": \"ground\", \"ContextObject (Label)\": \"\", \"constraint\": \"\", \"Constraint component\": \"\", \"Applicable units of measure\": \"m2 ha-1\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"abundance\", \"Property (Label)\": \"abundance\", \"ObjectOfInterest (Label)\": \"coarse woody debris\", \"Matrix (Label)\": \"hectare\", \"ContextObject (Label)\": \"forest\", \"constraint\": [\"measured from all plots/transects\", \"scaled to a hectare\"], \"Constraint component\": [\"plots/transects\", \"hectare\"], \"Applicable units of measure\": \"m\\u00b2 ha\\u207b\\u00b9\"}\n",
      "--------------------------------------------------\n",
      "File: variable_8.0.json\n",
      "Model: openai/gpt-4o-mini\n",
      "Variable: Coarse woody debris abundance\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"coarse woody debris\", \"Matrix (Label)\": \"ground\", \"ContextObject (Label)\": \"\", \"constraint\": \"\", \"Constraint component\": \"\", \"Applicable units of measure\": \"m2 ha-1\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"mean\", \"Property (Label)\": \"abundance\", \"ObjectOfInterest (Label)\": \"coarse woody debris\", \"Matrix (Label)\": \"forest ecosystem\", \"ContextObject (Label)\": \"hectare\", \"constraint\": \"calculated from plots/transects\", \"Constraint component\": \"coarse woody debris, abundance\", \"Applicable units of measure\": \"m2/ha\"}\n",
      "--------------------------------------------------\n",
      "File: variable_8.0.json\n",
      "Model: openai/gpt-4.1-mini\n",
      "Variable: Coarse woody debris abundance\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"coarse woody debris\", \"Matrix (Label)\": \"ground\", \"ContextObject (Label)\": \"\", \"constraint\": \"\", \"Constraint component\": \"\", \"Applicable units of measure\": \"m2 ha-1\"}\n",
      "LLM Output: {\"Property (Label)\": \"abundance\", \"ObjectOfInterest (Label)\": \"coarse woody debris\", \"Matrix (Label)\": \"forest floor\", \"ContextObject (Label)\": \"plot or transect\", \"constraint\": \"scaled to a hectare (100 x 100 m)\", \"Constraint component\": [\"coarse woody debris\", \"abundance\"], \"Applicable units of measure\": \"m2 hectare-1\"}\n",
      "--------------------------------------------------\n",
      "File: variable_2.0.json\n",
      "Model: mistralai/mistral-7b-instruct\n",
      "Variable: Air daily maximum temperature\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"ContextObject (Label)\": \"\", \"constraint\": [\"daily\", \"1,7 m aboveground\"], \"Constraint component\": [\"maximum\", \"air\"], \"Applicable units of measure\": \"Celsius\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"maximum\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"ContextObject (Label)\": \"height\", \"constraint\": \"daily\", \"Constraint component\": [\"air\", \"temperature\", \"daily\"], \"Applicable units of measure\": \"\\u00b0C\"}\n",
      "--------------------------------------------------\n",
      "File: variable_2.0.json\n",
      "Model: mistralai/mistral-small-24b-instruct-2501\n",
      "Variable: Air daily maximum temperature\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"ContextObject (Label)\": \"\", \"constraint\": [\"daily\", \"1,7 m aboveground\"], \"Constraint component\": [\"maximum\", \"air\"], \"Applicable units of measure\": \"Celsius\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"maximum\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"ContextObject (Label)\": \"height\", \"constraint\": [\"at a height of 1.7 meters\", \"daily\"], \"Constraint component\": [\"air\", \"temperature\"], \"Applicable units of measure\": \"\\u00b0C\"}\n",
      "--------------------------------------------------\n",
      "File: variable_2.0.json\n",
      "Model: meta-llama/llama-3.2-11b-vision-instruct\n",
      "Variable: Air daily maximum temperature\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"ContextObject (Label)\": \"\", \"constraint\": [\"daily\", \"1,7 m aboveground\"], \"Constraint component\": [\"maximum\", \"air\"], \"Applicable units of measure\": \"Celsius\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"maximum\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Applicable units of measure\": \"\\u00b0C\"}\n",
      "--------------------------------------------------\n",
      "File: variable_2.0.json\n",
      "Model: meta-llama/llama-3.3-70b-instruct\n",
      "Variable: Air daily maximum temperature\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"ContextObject (Label)\": \"\", \"constraint\": [\"daily\", \"1,7 m aboveground\"], \"Constraint component\": [\"maximum\", \"air\"], \"Applicable units of measure\": \"Celsius\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"maximum\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"ContextObject (Label)\": \"daily\", \"constraint\": [\"at a height of 1.7 meters\"], \"Constraint component\": [\"air\", \"temperature\"], \"Applicable units of measure\": \"\\u00b0C\"}\n",
      "--------------------------------------------------\n",
      "File: variable_2.0.json\n",
      "Model: deepseek/deepseek-r1-distill-qwen-14b\n",
      "Variable: Air daily maximum temperature\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"ContextObject (Label)\": \"\", \"constraint\": [\"daily\", \"1,7 m aboveground\"], \"Constraint component\": [\"maximum\", \"air\"], \"Applicable units of measure\": \"Celsius\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"maximum\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"ContextObject (Label)\": \"1.7 meters above ground level\", \"constraint\": [\"daily maximum\", \"at 1.7 meters above ground level\"], \"Constraint component\": [\"air\", \"temperature\"], \"Applicable units of measure\": \"\\u00b0C\"}\n",
      "--------------------------------------------------\n",
      "File: variable_2.0.json\n",
      "Model: openai/gpt-4o-mini\n",
      "Variable: Air daily maximum temperature\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"ContextObject (Label)\": \"\", \"constraint\": [\"daily\", \"1,7 m aboveground\"], \"Constraint component\": [\"maximum\", \"air\"], \"Applicable units of measure\": \"Celsius\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"maximum\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"constraint\": [\"measured at a height of 1.7 meters\", \"daily maximum\"], \"Constraint component\": [\"air\", \"temperature\"], \"Applicable units of measure\": \"\\u00b0C\"}\n",
      "--------------------------------------------------\n",
      "File: variable_2.0.json\n",
      "Model: openai/gpt-4.1-mini\n",
      "Variable: Air daily maximum temperature\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"ContextObject (Label)\": \"\", \"constraint\": [\"daily\", \"1,7 m aboveground\"], \"Constraint component\": [\"maximum\", \"air\"], \"Applicable units of measure\": \"Celsius\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"maximum\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"ContextObject (Label)\": \"height of 1.7 meters\", \"constraint\": [\"measured at 1.7 meters height\", \"daily maximum\"], \"Constraint component\": [\"air\", \"temperature\"], \"Applicable units of measure\": \"\\u00b0C\"}\n",
      "--------------------------------------------------\n",
      "File: variable_9.0.json\n",
      "Model: mistralai/mistral-7b-instruct\n",
      "Variable: Foliage projective cover in the lower canopy strata\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"foliage\", \"Matrix (Label)\": \"ground\", \"ContextObject (Label)\": \"\", \"constraint\": \"lower canopy strata\", \"Constraint component\": \"foliage\", \"Applicable units of measure\": \"dimensionless\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"proportion\", \"Property (Label)\": \"coverage\", \"ObjectOfInterest (Label)\": \"foliage\", \"Matrix (Label)\": \"lower canopy strata\", \"ContextObject (Label)\": \"ground\", \"constraint\": \"in a vertical plane\", \"Constraint component\": [\"coverage\", \"vertical plane\"], \"Applicable units of measure\": \"%\"}\n",
      "--------------------------------------------------\n",
      "File: variable_9.0.json\n",
      "Model: mistralai/mistral-small-24b-instruct-2501\n",
      "Variable: Foliage projective cover in the lower canopy strata\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"foliage\", \"Matrix (Label)\": \"ground\", \"ContextObject (Label)\": \"\", \"constraint\": \"lower canopy strata\", \"Constraint component\": \"foliage\", \"Applicable units of measure\": \"dimensionless\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"proportion\", \"Property (Label)\": \"cover\", \"ObjectOfInterest (Label)\": \"foliage\", \"Matrix (Label)\": \"ground\", \"ContextObject (Label)\": \"lower canopy strata\", \"constraint\": [\"in a vertical plane\", \"expressed as a percentage\"], \"Constraint component\": [\"foliage\", \"cover\"], \"Applicable units of measure\": \"%\"}\n",
      "--------------------------------------------------\n",
      "File: variable_9.0.json\n",
      "Model: meta-llama/llama-3.2-11b-vision-instruct\n",
      "Variable: Foliage projective cover in the lower canopy strata\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"foliage\", \"Matrix (Label)\": \"ground\", \"ContextObject (Label)\": \"\", \"constraint\": \"lower canopy strata\", \"Constraint component\": \"foliage\", \"Applicable units of measure\": \"dimensionless\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"proportion\", \"Property (Label)\": \"cover\", \"ObjectOfInterest (Label)\": \"foliage\", \"Matrix (Label)\": \"canopy\", \"ContextObject (Label)\": \"ground\", \"constraint\": [\"in the lower canopy strata\"], \"Constraint component\": [\"canopy\", \"strata\"], \"Applicable units of measure\": \"%\"}\n",
      "--------------------------------------------------\n",
      "File: variable_9.0.json\n",
      "Model: meta-llama/llama-3.3-70b-instruct\n",
      "Variable: Foliage projective cover in the lower canopy strata\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"foliage\", \"Matrix (Label)\": \"ground\", \"ContextObject (Label)\": \"\", \"constraint\": \"lower canopy strata\", \"Constraint component\": \"foliage\", \"Applicable units of measure\": \"dimensionless\"}\n",
      "LLM Output: {}\n",
      "--------------------------------------------------\n",
      "File: variable_9.0.json\n",
      "Model: deepseek/deepseek-r1-distill-qwen-14b\n",
      "Variable: Foliage projective cover in the lower canopy strata\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"foliage\", \"Matrix (Label)\": \"ground\", \"ContextObject (Label)\": \"\", \"constraint\": \"lower canopy strata\", \"Constraint component\": \"foliage\", \"Applicable units of measure\": \"dimensionless\"}\n",
      "LLM Output: {\"Property (Label)\": \"proportion\", \"ObjectOfInterest (Label)\": \"foliage\", \"Matrix (Label)\": \"vegetation\", \"ContextObject (Label)\": \"lower canopy strata\", \"constraint\": [\"lower canopy strata\", \"projective cover\"], \"Constraint component\": [\"lower canopy\", \"projective cover\"], \"Applicable units of measure\": \"percent\"}\n",
      "--------------------------------------------------\n",
      "File: variable_9.0.json\n",
      "Model: openai/gpt-4o-mini\n",
      "Variable: Foliage projective cover in the lower canopy strata\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"foliage\", \"Matrix (Label)\": \"ground\", \"ContextObject (Label)\": \"\", \"constraint\": \"lower canopy strata\", \"Constraint component\": \"foliage\", \"Applicable units of measure\": \"dimensionless\"}\n",
      "LLM Output: {\"Property (Label)\": \"projective cover\", \"ObjectOfInterest (Label)\": \"foliage\", \"Matrix (Label)\": \"lower canopy strata\", \"Applicable units of measure\": \"percentage (%)\"}\n",
      "--------------------------------------------------\n",
      "File: variable_9.0.json\n",
      "Model: openai/gpt-4.1-mini\n",
      "Variable: Foliage projective cover in the lower canopy strata\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"foliage\", \"Matrix (Label)\": \"ground\", \"ContextObject (Label)\": \"\", \"constraint\": \"lower canopy strata\", \"Constraint component\": \"foliage\", \"Applicable units of measure\": \"dimensionless\"}\n",
      "LLM Output: {\"Property (Label)\": \"projective cover\", \"ObjectOfInterest (Label)\": \"foliage\", \"Matrix (Label)\": \"ground area\", \"ContextObject (Label)\": \"lower canopy strata\", \"Applicable units of measure\": \"percentage\"}\n",
      "--------------------------------------------------\n",
      "File: variable_16.0.json\n",
      "Model: mistralai/mistral-7b-instruct\n",
      "Variable: Standard metabolic rate in mg of Oxygen per hour\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"mass flow rate\", \"ObjectOfInterest (Label)\": \"oxygen\", \"Matrix (Label)\": \"organism\", \"ContextObject (Label)\": \"\", \"constraint\": [\"ectotherm\", \"due to metabolism\", \"non-active\", \"non-stressed\"], \"Constraint component\": [\"animal\", \"mass flow rate\"], \"Applicable units of measure\": \"mg h-1\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"average\", \"Property (Label)\": \"oxygen consumption rate\", \"ObjectOfInterest (Label)\": \"ectotherm animal\", \"Matrix (Label)\": \"environment\", \"ContextObject (Label)\": \"baseline state\", \"constraint\": [\"non-active\", \"non-stressed\"], \"Constraint component\": [\"oxygen consumption\", \"time period\"], \"Applicable units of measure\": \"mg O2/hour\"}\n",
      "--------------------------------------------------\n",
      "File: variable_16.0.json\n",
      "Model: mistralai/mistral-small-24b-instruct-2501\n",
      "Variable: Standard metabolic rate in mg of Oxygen per hour\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"mass flow rate\", \"ObjectOfInterest (Label)\": \"oxygen\", \"Matrix (Label)\": \"organism\", \"ContextObject (Label)\": \"\", \"constraint\": [\"ectotherm\", \"due to metabolism\", \"non-active\", \"non-stressed\"], \"Constraint component\": [\"animal\", \"mass flow rate\"], \"Applicable units of measure\": \"mg h-1\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"baseline\", \"Property (Label)\": \"metabolic rate\", \"ObjectOfInterest (Label)\": \"ectotherm animal\", \"Matrix (Label)\": \"oxygen\", \"ContextObject (Label)\": \"non-active, non-stressed\", \"constraint\": [\"baseline metabolic rate\", \"non-active, non-stressed\"], \"Constraint component\": [\"ectotherm animal\", \"metabolic rate\"], \"Applicable units of measure\": \"mg O2 h-1\"}\n",
      "--------------------------------------------------\n",
      "File: variable_16.0.json\n",
      "Model: meta-llama/llama-3.2-11b-vision-instruct\n",
      "Variable: Standard metabolic rate in mg of Oxygen per hour\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"mass flow rate\", \"ObjectOfInterest (Label)\": \"oxygen\", \"Matrix (Label)\": \"organism\", \"ContextObject (Label)\": \"\", \"constraint\": [\"ectotherm\", \"due to metabolism\", \"non-active\", \"non-stressed\"], \"Constraint component\": [\"animal\", \"mass flow rate\"], \"Applicable units of measure\": \"mg h-1\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"average\", \"Property (Label)\": \"metabolic rate\", \"ObjectOfInterest (Label)\": \"ectotherm animal\", \"Applicable units of measure\": \"mg/h\"}\n",
      "--------------------------------------------------\n",
      "File: variable_16.0.json\n",
      "Model: meta-llama/llama-3.3-70b-instruct\n",
      "Variable: Standard metabolic rate in mg of Oxygen per hour\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"mass flow rate\", \"ObjectOfInterest (Label)\": \"oxygen\", \"Matrix (Label)\": \"organism\", \"ContextObject (Label)\": \"\", \"constraint\": [\"ectotherm\", \"due to metabolism\", \"non-active\", \"non-stressed\"], \"Constraint component\": [\"animal\", \"mass flow rate\"], \"Applicable units of measure\": \"mg h-1\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"None\", \"Property (Label)\": \"metabolic rate\", \"ObjectOfInterest (Label)\": \"ectotherm animal\", \"Matrix (Label)\": \"atmosphere\", \"ContextObject (Label)\": \"basal condition\", \"constraint\": \"non-active, non-stressed\", \"Constraint component\": \"metabolic rate, ectotherm animal\", \"Applicable units of measure\": \"mg O2 h-1\"}\n",
      "--------------------------------------------------\n",
      "File: variable_16.0.json\n",
      "Model: deepseek/deepseek-r1-distill-qwen-14b\n",
      "Variable: Standard metabolic rate in mg of Oxygen per hour\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"mass flow rate\", \"ObjectOfInterest (Label)\": \"oxygen\", \"Matrix (Label)\": \"organism\", \"ContextObject (Label)\": \"\", \"constraint\": [\"ectotherm\", \"due to metabolism\", \"non-active\", \"non-stressed\"], \"Constraint component\": [\"animal\", \"mass flow rate\"], \"Applicable units of measure\": \"mg h-1\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"mean\", \"Property (Label)\": \"metabolic rate\", \"ObjectOfInterest (Label)\": \"ectotherm animal\", \"Matrix (Label)\": \"animal body\", \"ContextObject (Label)\": \"baseline physiological state\", \"constraint\": [\"ectotherm animal\", \"baseline\", \"non-active\", \"non-stressed\", \"mg of Oxygen per hour\"], \"Constraint component\": [\"ectotherm animal\", \"baseline\", \"non-active\", \"non-stressed\", \"oxygen consumption rate\"], \"Applicable units of measure\": \"mg O2 h-1\"}\n",
      "--------------------------------------------------\n",
      "File: variable_16.0.json\n",
      "Model: openai/gpt-4o-mini\n",
      "Variable: Standard metabolic rate in mg of Oxygen per hour\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"mass flow rate\", \"ObjectOfInterest (Label)\": \"oxygen\", \"Matrix (Label)\": \"organism\", \"ContextObject (Label)\": \"\", \"constraint\": [\"ectotherm\", \"due to metabolism\", \"non-active\", \"non-stressed\"], \"Constraint component\": [\"animal\", \"mass flow rate\"], \"Applicable units of measure\": \"mg h-1\"}\n",
      "LLM Output: {\"Statistical Modifier (Label)\": \"baseline\", \"Property (Label)\": \"metabolic rate\", \"ObjectOfInterest (Label)\": \"ectotherm animal\", \"Applicable units of measure\": \"mg h-1 O2\"}\n",
      "--------------------------------------------------\n",
      "File: variable_16.0.json\n",
      "Model: openai/gpt-4.1-mini\n",
      "Variable: Standard metabolic rate in mg of Oxygen per hour\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"mass flow rate\", \"ObjectOfInterest (Label)\": \"oxygen\", \"Matrix (Label)\": \"organism\", \"ContextObject (Label)\": \"\", \"constraint\": [\"ectotherm\", \"due to metabolism\", \"non-active\", \"non-stressed\"], \"Constraint component\": [\"animal\", \"mass flow rate\"], \"Applicable units of measure\": \"mg h-1\"}\n",
      "LLM Output: {\"Property (Label)\": \"metabolic rate\", \"ObjectOfInterest (Label)\": \"ectotherm animal\", \"ContextObject (Label)\": \"baseline metabolic state\", \"constraint\": [\"non-active\", \"non-stressed\"], \"Constraint component\": [\"ectotherm animal\", \"metabolic rate\"], \"Applicable units of measure\": \"mg O2 h-1\"}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 10) Finally, show ground truth and LLM outputs after the summary\n",
    "print(\"\\n=== Ground Truth vs. LLM Output Details ===\\n\")\n",
    "for idx, row in df_results.iterrows():\n",
    "    print(\"File:\", row[\"File\"])\n",
    "    print(\"Model:\", row[\"Model\"])\n",
    "    print(\"Variable:\", row[\"Variable\"])\n",
    "    print(\"Ground Truth:\", row[\"GroundTruth\"])\n",
    "    print(\"LLM Output:\", row[\"LLMOutput\"])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0fd7451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔︎ Appended results and metadata to /Users/rastegar-a/Documents/GitHub/i-adopt-llm-based-service/benchmarking_example/benchmarking_outputs/i_adopt_benchmark_history.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ---------- run‑specific metadata ----------\n",
    "run_id         = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "experiment_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "variables_ran   = sorted({f for f in df_results[\"File\"]})\n",
    "models_ran      = model_names                        # already defined\n",
    "\n",
    "df_meta = pd.DataFrame(\n",
    "    {\n",
    "        \"run_id\":      [run_id],\n",
    "        \"timestamp\":   [experiment_time],\n",
    "        \"variables\":   [\", \".join(variables_ran)],\n",
    "        \"models\":      [\", \".join(models_ran)],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create output dir if it doesn't exist\n",
    "out_dir = pathlib.Path(\"benchmarking_outputs\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "history_file = out_dir / \"i_adopt_benchmark_history.xlsx\"\n",
    "\n",
    "summary_combined = pd.merge(\n",
    "    summary_embed, summary_exact,\n",
    "    on=\"Model\",\n",
    "    suffixes=(\"_embed\", \"_exact\")\n",
    ")\n",
    "\n",
    "# 1. Write or append to the workbook\n",
    "if not history_file.exists():\n",
    "    # First run: create file and write everything from scratch\n",
    "    with pd.ExcelWriter(history_file, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "        # Create a persistent meta sheet with headers\n",
    "        df_meta.to_excel(writer, sheet_name=\"meta\", index=False)\n",
    "\n",
    "        # First summary sheet (combined metrics)\n",
    "        summary_combined.to_excel(writer, sheet_name=f\"summary_{run_id}\", index=False)\n",
    "\n",
    "        # Full results\n",
    "        df_results.to_excel(writer, sheet_name=f\"rows_{run_id}\", index=False)\n",
    "\n",
    "else:\n",
    "    # File exists: append one row to meta, add new result sheets\n",
    "    with pd.ExcelWriter(history_file, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"overlay\") as writer:\n",
    "        # Add new sheets\n",
    "        summary_combined.to_excel(writer, sheet_name=f\"summary_{run_id}\", index=False)\n",
    "        df_results.to_excel(writer, sheet_name=f\"rows_{run_id}\", index=False)\n",
    "\n",
    "    # Now append meta manually using openpyxl\n",
    "    wb = load_workbook(history_file)\n",
    "    ws = wb[\"meta\"]\n",
    "    next_row = ws.max_row + 1\n",
    "    for col_idx, val in enumerate(df_meta.iloc[0], start=1):\n",
    "        ws.cell(row=next_row, column=col_idx, value=val)\n",
    "    wb.save(history_file)\n",
    "    wb.close()\n",
    "\n",
    "print(f\"✔︎ Appended results and metadata to {history_file.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd826f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae66d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
