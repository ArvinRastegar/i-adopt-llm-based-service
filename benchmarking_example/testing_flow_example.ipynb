{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8cf496",
   "metadata": {},
   "source": [
    "Implementing evaluation mertics on a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c71fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai\n",
    "# !pip install langchain\n",
    "# !pip install pandas\n",
    "# !pip install -U sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b8f0fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f01f0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 24 JSON files in /Users/rastegar-a/Documents/GitHub/i-adopt-llm-based-service/benchmarking_example/data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p0/j3zv3dzs5t38v7sm55wkjycr000fvr/T/ipykernel_12973/2687494125.py:12: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.iloc[:, 0] = df.iloc[:, 0].fillna(method=\"ffill\")\n"
     ]
    }
   ],
   "source": [
    "# Path to your CSV file\n",
    "csv_path = \"/Users/rastegar-a/Documents/GitHub/i-adopt-llm-based-service/benchmarking_example/data/Challenge variable descriptions version 2 - agreed solutions 2.csv\"\n",
    "\n",
    "# Output folder\n",
    "output_folder = \"/Users/rastegar-a/Documents/GitHub/i-adopt-llm-based-service/benchmarking_example/data\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Read the CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Forward-fill the first column to group related rows\n",
    "df.iloc[:, 0] = df.iloc[:, 0].fillna(method=\"ffill\")\n",
    "\n",
    "# Get column names\n",
    "columns = df.columns.tolist()\n",
    "\n",
    "# Group by first column (variable ID or index)\n",
    "grouped = df.groupby(columns[0])\n",
    "\n",
    "for var_id, group in grouped:\n",
    "    # Choose the variable name from the first non-null \"Variable Name\" entry\n",
    "    var_name = str(group.iloc[0].get(\"Variable Name\", f\"variable_{var_id}\")).strip()\n",
    "    var_name_clean = var_name.replace(\" \", \"_\").replace(\"/\", \"_\") or f\"variable_{var_id}\"\n",
    "\n",
    "    json_filename = f\"{var_name_clean}.json\"\n",
    "    json_path = os.path.join(output_folder, json_filename)\n",
    "\n",
    "    # Create a dictionary where each key is a column name\n",
    "    # and each value is:\n",
    "    # - a single string if only one unique non-null value\n",
    "    # - a list if multiple unique non-null values\n",
    "    variable_dict = {}\n",
    "    for col in columns[1:]:  # Skip the index/grouping column\n",
    "        values = group[col].dropna().unique().tolist()\n",
    "        if not values:\n",
    "            continue\n",
    "        variable_dict[col] = values[0] if len(values) == 1 else values\n",
    "\n",
    "    # Save JSON\n",
    "    with open(json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(variable_dict, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Created {len(grouped)} JSON files in {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca643a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the folder path\n",
    "# folder_path = \"/Users/rastegar-a/Documents/GitHub/i-adopt-llm-based-service/RDF-modelling-examples/Annotated_variables/\"\n",
    "# # Loop through all files in the folder\n",
    "# for filename in os.listdir(folder_path):\n",
    "#     if filename.endswith(\".csv\"):\n",
    "#         csv_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "#         # Read the CSV file\n",
    "#         df = pd.read_csv(csv_path)\n",
    "        \n",
    "#         # Define JSON output path\n",
    "#         json_filename = filename.replace(\".csv\", \".json\")\n",
    "#         json_path = os.path.join(\"/Users/rastegar-a/Documents/GitHub/i-adopt-llm-based-service/benchmarking_example/\", json_filename)\n",
    "        \n",
    "#         # Convert to JSON\n",
    "#         df.to_json(json_path, orient=\"records\", lines=True)\n",
    "        \n",
    "#         print(f\"Converted {filename} to {json_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84703d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Load from .env file in current directory\n",
    "load_dotenv()\n",
    "\n",
    "# Get the token from the environment\n",
    "hf_token = os.getenv(\"hugging_face_api_key\")\n",
    "\n",
    "# Optional: check if token is loaded\n",
    "if not hf_token:\n",
    "    raise ValueError(\"HUGGINGFACE_HUB_TOKEN not found in .env\")\n",
    "\n",
    "# Login to Hugging Face Hub\n",
    "login(token=hf_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a469c",
   "metadata": {},
   "source": [
    "Variable 1, 4 and 10 are given as examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b98103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Prompt template for asking the model to decompose the variable\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are a knowledge engineer and a climate change scientist. I need you to model a climate change variable using the I-ADOPT framework. A variable is usually the result of a sensor measurement or of a laboratory analysis on a sample. The task is to generate Json code with a description of the variable according to the I-ADOPT ontology. See the following examples: \n",
    "Example 1:\n",
    "{{\n",
    "  \"Provided Variable Name\": \"Electron density in the solar wind\",\n",
    "  \"Definition\": \"Density (particle per cm3) of electrons measured in the Solar Wind.\",\n",
    "  \"Property (Label)\": \"volumetric number density\",\n",
    "  \"ObjectOfInterest (Label)\": \"electron\",\n",
    "  \"Matrix (Label)\": \"solar wind\",\n",
    "  \"Applicable units of measure\": \"cm-3\"\n",
    "}}\n",
    "Example 2:\n",
    "{{\n",
    "  \"Provided Variable Name\": \"Atmospheric boundary layer height defined by temperature inversion\",\n",
    "  \"Definition\": \"Atmospheric boundary layer height defined by temperature inversion.\",\n",
    "  \"Property (Label)\": \"height\",\n",
    "  \"ObjectOfInterest (Label)\": \"atmospheric boundary layer\",\n",
    "  \"Matrix (Label)\": \"atmosphere\",\n",
    "  \"constraint\": [\n",
    "    \"defined by temperature inversion\",\n",
    "    \"above the valley floor\"\n",
    "  ],\n",
    "  \"Constraint component\": [\n",
    "    \"atmospheric boundary layer\",\n",
    "    \"height\"\n",
    "  ],\n",
    "  \"Applicable units of measure\": \"m\"\n",
    "}}\n",
    "Example 3:\n",
    "{{\n",
    "  \"Provided Variable Name\": \"Peak ground acceleration\",\n",
    "  \"Definition\": \"Peak acceleration measured on the earth surface when facing seismic events, like earthquakes.\",\n",
    "  \"Statistical Modifier\": \"maximum\",\n",
    "  \"Property (Label)\": \"acceleration\",\n",
    "  \"ObjectOfInterest (Label)\": \"ground\",\n",
    "  \"constraint\": [\n",
    "    \"surface\",\n",
    "    \"during seismic events\"\n",
    "  ],\n",
    "  \"Constraint component\": [\n",
    "    \"ground\",\n",
    "    \"acceleration\"\n",
    "  ],\n",
    "  \"Applicable units of measure\": \"m s-2\"\n",
    "}}\n",
    "Given the example above. model the following variable:\n",
    "Variable: {variable}\n",
    "Description: {description}\n",
    "Decompose it into:\n",
    "- Statistical Modifier (Label) --OPTIONAL--\n",
    "- Property (Label)\n",
    "- ObjectOfInterest (Label)\n",
    "- Matrix (Label) --OPTIONAL--\n",
    "- ContextObject (Label) --OPTIONAL--\n",
    "- constraint --OPTIONAL--\n",
    "- Constraint component --OPTIONAL--\n",
    "- Applicable units of measure --OPTIONAL--\n",
    "Return a JSON in this exact format:\n",
    "{{\n",
    "  \"Provided Variable Name\": \"...\",\n",
    "  \"Definition\": \"...\",\n",
    "  \"Statistical Modifier (Label)\": \"...\",\n",
    "  \"Property (Label)\": \"...\", \n",
    "  \"ObjectOfInterest (Label)\": \"...\",\n",
    "  \"Matrix (Label)\": \"...\",\n",
    "  \"ContextObject (Label)\": \"...\",\n",
    "  \"constraint\": \"...\"\n",
    "  \"Constraint component\": \"...\",\n",
    "  \"Applicable units of measure\": \"...\"\n",
    "}}\n",
    "\"\"\",\n",
    "    input_variables=[\"variable\", \"description\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbfff24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_from_response(response_text):\n",
    "    \"\"\"\n",
    "    Extract the first valid JSON object from the response text.\n",
    "    Cleans up common formatting like ```json or plain ``` fences.\n",
    "    \"\"\"\n",
    "    # Remove code block markers like ```json or ```\n",
    "    cleaned_text = re.sub(r\"```(?:json)?\", \"\", response_text).strip()\n",
    "\n",
    "    # Attempt to extract a JSON-like structure using regex\n",
    "    match = re.search(r\"\\{.*\\}\", cleaned_text, re.DOTALL)\n",
    "    if match:\n",
    "        json_str = match.group(0)\n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"JSON decoding failed:\", e)\n",
    "            return {}\n",
    "    else:\n",
    "        print(\"No JSON found in response.\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07989f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Folder containing JSON files (each file has one ground-truth variable record)\n",
    "json_folder = \"/Users/rastegar-a/Documents/GitHub/i-adopt-llm-based-service/benchmarking_example/data/\"\n",
    "json_folder = \"/Users/rastegar-a/Documents/GitHub/i-adopt-llm-based-service/benchmarking_example/data/five_variables/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce33a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Models you want to compare on OpenRouter or OpenAI\n",
    "# model_names = [\"deepseek/deepseek-v3-base:free\", \"google/gemini-2.5-pro-exp-03-25:free\"] # OpenRouter models\n",
    "# model_names = [\"deepseek/deepseek-v3-base:free\"] # OpenRouter models\n",
    "####### ----\n",
    "model_names = [\n",
    "    \"mistralai/mistral-7b-instruct\",\n",
    "    \"mistralai/mistral-small-24b-instruct-2501\",\n",
    "    \"meta-llama/llama-3.2-11b-vision-instruct\",\n",
    "    \"meta-llama/llama-3.3-70b-instruct\",\n",
    "    \"deepseek/deepseek-r1-distill-qwen-14b\",\n",
    "    \"openai/gpt-4o-mini\",\n",
    "    \"openai/gpt-4.1-mini\"\n",
    "]\n",
    "### Initialize OpenRouter client (replace <OPENROUTER_API_KEY> with your actual API key).\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),    \n",
    ")\n",
    "\n",
    "############ -----\n",
    "# model_names = [\"gpt-4o-mini\", \"gpt-4o\"]\n",
    "# client = OpenAI(\n",
    "#     api_key=os.getenv(\"OPENAI_API_KEY\"),    \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8305a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 5) LLM call helper using OpenRouter's chat endpoint\n",
    "def call_model_openrouter(model_name, user_prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        extra_headers={\n",
    "            \"HTTP-Referer\": \"<YOUR_SITE_URL>\",  # optional\n",
    "            \"X-Title\": \"<YOUR_SITE_NAME>\"       # optional\n",
    "        },\n",
    "        model=model_name,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    # print(f\"Model: {model_name}, Response: {response}\")\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 6) Embedding model (SentenceTransformer) for checking similarity\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def embedding_similarity(text1, text2):\n",
    "    \"\"\"Compute cosine similarity between two pieces of text.\"\"\"\n",
    "    emb1 = embed_model.encode(text1, convert_to_tensor=True)\n",
    "    emb2 = embed_model.encode(text2, convert_to_tensor=True)\n",
    "    return util.cos_sim(emb1, emb2).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e2962d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) We'll evaluate each of these keys with a threshold for correctness\n",
    "# ONTO_KEYS = [\"hasObjectOfInterest\", \"hasProperty\", \"hasMatrix\", \"hasConstraint\", \"constrain1\", \"hasContext\"]\n",
    "ONTO_KEYS =  [\"Statistical Modifier (Label)\", \"Property (Label)\", \"ObjectOfInterest (Label)\", \"Matrix (Label)\", \"Matrix (System)\", \"ContextObject (Label)\", \"constraint\", \"Constraint component\", \"Applicable units of measure\"]\n",
    "THRESHOLD = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56c88468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion_for_field(gt_val, pred_val, threshold=0.90):\n",
    "    \"\"\"\n",
    "    Correct Logic:\n",
    "      True Positive (TP):   GT not empty, pred not empty, similarity >= threshold\n",
    "      False Positive (FP):  GT empty, pred not empty\n",
    "      False Negative (FN):  GT not empty and (pred empty OR similarity < threshold)\n",
    "      True Negative (TN):   GT empty, pred empty\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert lists to string representations\n",
    "    if isinstance(gt_val, list):\n",
    "        gt_val = \", \".join(str(v).strip() for v in gt_val if v)\n",
    "    if isinstance(pred_val, list):\n",
    "        pred_val = \", \".join(str(v).strip() for v in pred_val if v)\n",
    "\n",
    "    # Strip leading/trailing whitespace\n",
    "    gt_val = gt_val.strip() if isinstance(gt_val, str) else \"\"\n",
    "    pred_val = pred_val.strip() if isinstance(pred_val, str) else \"\"\n",
    "\n",
    "    # If ground truth is non-empty => label is \"present\".\n",
    "    if gt_val:\n",
    "        # Prediction non-empty => check similarity\n",
    "        if pred_val:\n",
    "            sim = embedding_similarity(gt_val, pred_val)\n",
    "            if sim >= threshold:\n",
    "                return (1, 0, 0, 0)  # TP\n",
    "            else:\n",
    "                return (0, 0, 1, 0)  # FN (prediction too dissimilar)\n",
    "        else:\n",
    "            # Prediction empty => definitely FN\n",
    "            return (0, 0, 1, 0)\n",
    "    \n",
    "    # If ground truth is empty => label is \"absent\".\n",
    "    else:\n",
    "        if pred_val:\n",
    "            # Predicted something when nothing was needed => FP\n",
    "            return (0, 1, 0, 0)\n",
    "        else:\n",
    "            # Both empty => TN\n",
    "            return (0, 0, 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "# Helper to compute precision, recall, f1 from confusion matrix totals\n",
    "def precision_recall_f1(tp, fp, fn, tn):\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    if precision + recall == 0:\n",
    "        f1 = 0.0\n",
    "    else:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfd97d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON decoding failed: Extra data: line 10 column 1 (char 364)\n",
      "JSON decoding failed: Extra data: line 12 column 1 (char 331)\n"
     ]
    }
   ],
   "source": [
    "# 8) Main loop over JSON files\n",
    "all_rows = []  # We'll store row-based results to build a DF\n",
    "\n",
    "for file_name in os.listdir(json_folder):\n",
    "    if file_name.endswith(\".json\"):\n",
    "        with open(os.path.join(json_folder, file_name), \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Failed to parse {file_name}: {e}\")\n",
    "                continue\n",
    "\n",
    "            variable_text = data.get(\"Provided Variable Name\", \"\")\n",
    "            description_text = data.get(\"Definition\", \"\")\n",
    "            ground_truth = {k: data.get(k, \"\") for k in ONTO_KEYS}\n",
    "            prompt_text = prompt_template.format(\n",
    "                variable=variable_text,\n",
    "                description=description_text\n",
    "            )\n",
    "\n",
    "            # For each model, get predictions and compute confusion matrix\n",
    "            for model_name in model_names:\n",
    "                llm_output = call_model_openrouter(model_name, prompt_text)\n",
    "                # --- Remove code fences if present ---\n",
    "                # This will remove any ``` or ```json lines\n",
    "                # cleaned_output = re.sub(r\"```(\\w+)?\", \"\", llm_output).strip()\n",
    "\n",
    "                # Attempt to parse the cleaned string as JSON\n",
    "                predicted_json = extract_json_from_response(llm_output)\n",
    "\n",
    "                # Accumulate confusion counts across all keys\n",
    "                total_tp = total_fp = total_fn = total_tn = 0\n",
    "                for key in ONTO_KEYS:\n",
    "                    gt_val = ground_truth.get(key, \"\") or \"\"\n",
    "                    pred_val = predicted_json.get(key, \"\") or \"\"\n",
    "                    # print(f\"GT: {gt_val}, Pred: {pred_val}\")\n",
    "                    tp, fp, fn, tn = compute_confusion_for_field(gt_val, pred_val)\n",
    "                    total_tp += tp\n",
    "                    total_fp += fp\n",
    "                    total_fn += fn\n",
    "                    total_tn += tn\n",
    "\n",
    "                prec, rec, f1 = precision_recall_f1(total_tp, total_fp, total_fn, total_tn)\n",
    "\n",
    "                # Store everything in all_rows, including ground truth & the predicted JSON\n",
    "                row_dict = {\n",
    "                    \"File\": file_name,\n",
    "                    \"Variable\": variable_text,\n",
    "                    \"Model\": model_name,\n",
    "                    \"TP\": total_tp,\n",
    "                    \"FP\": total_fp,\n",
    "                    \"FN\": total_fn,\n",
    "                    \"TN\": total_tn,\n",
    "                    \"Precision\": round(prec, 3),\n",
    "                    \"Recall\": round(rec, 3),\n",
    "                    \"F1\": round(f1, 3),\n",
    "                    # Store ground truth & predicted as strings for easy reference\n",
    "                    \"GroundTruth\": json.dumps(ground_truth),\n",
    "                    \"LLMOutput\": json.dumps(predicted_json)\n",
    "                }\n",
    "                all_rows.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f00dfa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Results DataFrame ===\n",
      "\n",
      "                  File                                           Variable  \\\n",
      "0   variable_15.0.json                       Foraminifera, planktic, size   \n",
      "1   variable_15.0.json                       Foraminifera, planktic, size   \n",
      "2   variable_15.0.json                       Foraminifera, planktic, size   \n",
      "3   variable_15.0.json                       Foraminifera, planktic, size   \n",
      "4   variable_15.0.json                       Foraminifera, planktic, size   \n",
      "5   variable_15.0.json                       Foraminifera, planktic, size   \n",
      "6   variable_15.0.json                       Foraminifera, planktic, size   \n",
      "7    variable_2.0.json                      Air daily maximum temperature   \n",
      "8    variable_2.0.json                      Air daily maximum temperature   \n",
      "9    variable_2.0.json                      Air daily maximum temperature   \n",
      "10   variable_2.0.json                      Air daily maximum temperature   \n",
      "11   variable_2.0.json                      Air daily maximum temperature   \n",
      "12   variable_2.0.json                      Air daily maximum temperature   \n",
      "13   variable_2.0.json                      Air daily maximum temperature   \n",
      "14   variable_5.0.json  Atmosphere optical thickness of particulate or...   \n",
      "15   variable_5.0.json  Atmosphere optical thickness of particulate or...   \n",
      "16   variable_5.0.json  Atmosphere optical thickness of particulate or...   \n",
      "17   variable_5.0.json  Atmosphere optical thickness of particulate or...   \n",
      "18   variable_5.0.json  Atmosphere optical thickness of particulate or...   \n",
      "19   variable_5.0.json  Atmosphere optical thickness of particulate or...   \n",
      "20   variable_5.0.json  Atmosphere optical thickness of particulate or...   \n",
      "21   variable_3.0.json                                        Cloud cover   \n",
      "22   variable_3.0.json                                        Cloud cover   \n",
      "23   variable_3.0.json                                        Cloud cover   \n",
      "24   variable_3.0.json                                        Cloud cover   \n",
      "25   variable_3.0.json                                        Cloud cover   \n",
      "26   variable_3.0.json                                        Cloud cover   \n",
      "27   variable_3.0.json                                        Cloud cover   \n",
      "28  variable_28.0.json  Overnight stays in 3-star hotel near the sea s...   \n",
      "29  variable_28.0.json  Overnight stays in 3-star hotel near the sea s...   \n",
      "30  variable_28.0.json  Overnight stays in 3-star hotel near the sea s...   \n",
      "31  variable_28.0.json  Overnight stays in 3-star hotel near the sea s...   \n",
      "32  variable_28.0.json  Overnight stays in 3-star hotel near the sea s...   \n",
      "33  variable_28.0.json  Overnight stays in 3-star hotel near the sea s...   \n",
      "34  variable_28.0.json  Overnight stays in 3-star hotel near the sea s...   \n",
      "\n",
      "                                        Model  TP  FP  FN  TN  Precision  \\\n",
      "0               mistralai/mistral-7b-instruct   2   3   4   0      0.400   \n",
      "1   mistralai/mistral-small-24b-instruct-2501   3   2   3   1      0.600   \n",
      "2    meta-llama/llama-3.2-11b-vision-instruct   0   0   6   3      0.000   \n",
      "3           meta-llama/llama-3.3-70b-instruct   1   0   5   3      1.000   \n",
      "4       deepseek/deepseek-r1-distill-qwen-14b   1   1   5   2      0.500   \n",
      "5                          openai/gpt-4o-mini   2   3   4   0      0.400   \n",
      "6                         openai/gpt-4.1-mini   2   0   4   3      1.000   \n",
      "7               mistralai/mistral-7b-instruct   3   2   3   1      0.600   \n",
      "8   mistralai/mistral-small-24b-instruct-2501   3   3   3   0      0.500   \n",
      "9    meta-llama/llama-3.2-11b-vision-instruct   0   0   6   3      0.000   \n",
      "10          meta-llama/llama-3.3-70b-instruct   3   2   3   1      0.600   \n",
      "11      deepseek/deepseek-r1-distill-qwen-14b   3   3   3   0      0.500   \n",
      "12                         openai/gpt-4o-mini   3   3   3   0      0.500   \n",
      "13                        openai/gpt-4.1-mini   3   3   3   0      0.500   \n",
      "14              mistralai/mistral-7b-instruct   1   2   6   0      0.333   \n",
      "15  mistralai/mistral-small-24b-instruct-2501   0   0   7   2      0.000   \n",
      "16   meta-llama/llama-3.2-11b-vision-instruct   0   0   7   2      0.000   \n",
      "17          meta-llama/llama-3.3-70b-instruct   0   0   7   2      0.000   \n",
      "18      deepseek/deepseek-r1-distill-qwen-14b   1   0   6   2      1.000   \n",
      "19                         openai/gpt-4o-mini   1   0   6   2      1.000   \n",
      "20                        openai/gpt-4.1-mini   2   1   5   1      0.667   \n",
      "21              mistralai/mistral-7b-instruct   1   1   3   4      0.500   \n",
      "22  mistralai/mistral-small-24b-instruct-2501   1   5   3   0      0.167   \n",
      "23   meta-llama/llama-3.2-11b-vision-instruct   1   1   3   4      0.500   \n",
      "24          meta-llama/llama-3.3-70b-instruct   2   5   2   0      0.286   \n",
      "25      deepseek/deepseek-r1-distill-qwen-14b   1   2   3   3      0.333   \n",
      "26                         openai/gpt-4o-mini   0   0   4   5      0.000   \n",
      "27                        openai/gpt-4.1-mini   1   0   3   5      1.000   \n",
      "28              mistralai/mistral-7b-instruct   2   4   3   0      0.333   \n",
      "29  mistralai/mistral-small-24b-instruct-2501   3   4   2   0      0.429   \n",
      "30   meta-llama/llama-3.2-11b-vision-instruct   3   2   2   2      0.600   \n",
      "31          meta-llama/llama-3.3-70b-instruct   2   4   3   0      0.333   \n",
      "32      deepseek/deepseek-r1-distill-qwen-14b   4   2   1   2      0.667   \n",
      "33                         openai/gpt-4o-mini   2   3   3   1      0.400   \n",
      "34                        openai/gpt-4.1-mini   2   4   3   0      0.333   \n",
      "\n",
      "    Recall     F1                                        GroundTruth  \\\n",
      "0    0.333  0.364  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "1    0.500  0.545  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "2    0.000  0.000  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "3    0.167  0.286  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "4    0.167  0.250  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "5    0.333  0.364  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "6    0.333  0.500  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "7    0.500  0.545  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "8    0.500  0.500  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "9    0.000  0.000  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "10   0.500  0.545  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "11   0.500  0.500  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "12   0.500  0.500  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "13   0.500  0.500  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "14   0.143  0.200  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "15   0.000  0.000  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "16   0.000  0.000  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "17   0.000  0.000  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "18   0.143  0.250  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "19   0.143  0.250  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "20   0.286  0.400  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "21   0.250  0.333  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "22   0.250  0.200  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "23   0.250  0.333  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "24   0.500  0.364  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "25   0.250  0.286  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "26   0.000  0.000  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "27   0.250  0.400  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "28   0.400  0.364  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "29   0.600  0.500  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "30   0.600  0.600  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "31   0.400  0.364  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "32   0.800  0.727  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "33   0.400  0.400  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "34   0.400  0.364  {\"Statistical Modifier (Label)\": \"\", \"Property...   \n",
      "\n",
      "                                            LLMOutput  \n",
      "0   {\"Provided Variable Name\": \"Size of planktic f...  \n",
      "1   {\"Provided Variable Name\": \"Foraminifera, plan...  \n",
      "2                                                  {}  \n",
      "3   {\"Provided Variable Name\": \"Foraminifera, plan...  \n",
      "4   {\"Provided Variable Name\": \"Foraminifera, plan...  \n",
      "5   {\"Provided Variable Name\": \"Size of planktic f...  \n",
      "6   {\"Provided Variable Name\": \"Foraminifera, plan...  \n",
      "7   {\"Provided Variable Name\": \"Air daily maximum ...  \n",
      "8   {\"Provided Variable Name\": \"Air daily maximum ...  \n",
      "9                                                  {}  \n",
      "10  {\"Provided Variable Name\": \"Air daily maximum ...  \n",
      "11  {\"Provided Variable Name\": \"Air daily maximum ...  \n",
      "12  {\"Provided Variable Name\": \"Air daily maximum ...  \n",
      "13  {\"Provided Variable Name\": \"Air daily maximum ...  \n",
      "14  {\"Provided Variable Name\": \"Atmosphere optical...  \n",
      "15  {\"Provided Variable Name\": \"Atmosphere optical...  \n",
      "16  {\"Provided Variable Name\": \"Atmosphere optical...  \n",
      "17  {\"Provided Variable Name\": \"Atmosphere optical...  \n",
      "18  {\"Provided Variable Name\": \"Atmosphere optical...  \n",
      "19  {\"Provided Variable Name\": \"Atmosphere optical...  \n",
      "20  {\"Provided Variable Name\": \"Atmosphere optical...  \n",
      "21  {\"Provided Variable Name\": \"Cloud cover\", \"Def...  \n",
      "22  {\"Provided Variable Name\": \"Cloud cover\", \"Def...  \n",
      "23  {\"Provided Variable Name\": \"Cloud cover\", \"Def...  \n",
      "24  {\"Provided Variable Name\": \"Cloud cover\", \"Def...  \n",
      "25  {\"Provided Variable Name\": \"Cloud cover\", \"Def...  \n",
      "26  {\"Provided Variable Name\": \"Cloud cover\", \"Def...  \n",
      "27  {\"Provided Variable Name\": \"Cloud cover\", \"Def...  \n",
      "28  {\"Provided Variable Name\": \"Overnight stays in...  \n",
      "29  {\"Provided Variable Name\": \"Overnight stays in...  \n",
      "30  {\"Provided Variable Name\": \"Overnight stays in...  \n",
      "31  {\"Provided Variable Name\": \"Overnight stays in...  \n",
      "32  {\"Provided Variable Name\": \"Overnight stays in...  \n",
      "33  {\"Provided Variable Name\": \"Overnight stays in...  \n",
      "34  {\"Provided Variable Name\": \"Overnight stays in...  \n",
      "\n",
      "=== Summary (Grouped by File, Model) ===\n",
      "\n",
      "                  File                                      Model  Precision  \\\n",
      "0   variable_15.0.json      deepseek/deepseek-r1-distill-qwen-14b      0.500   \n",
      "1   variable_15.0.json   meta-llama/llama-3.2-11b-vision-instruct      0.000   \n",
      "2   variable_15.0.json          meta-llama/llama-3.3-70b-instruct      1.000   \n",
      "3   variable_15.0.json              mistralai/mistral-7b-instruct      0.400   \n",
      "4   variable_15.0.json  mistralai/mistral-small-24b-instruct-2501      0.600   \n",
      "5   variable_15.0.json                        openai/gpt-4.1-mini      1.000   \n",
      "6   variable_15.0.json                         openai/gpt-4o-mini      0.400   \n",
      "7    variable_2.0.json      deepseek/deepseek-r1-distill-qwen-14b      0.500   \n",
      "8    variable_2.0.json   meta-llama/llama-3.2-11b-vision-instruct      0.000   \n",
      "9    variable_2.0.json          meta-llama/llama-3.3-70b-instruct      0.600   \n",
      "10   variable_2.0.json              mistralai/mistral-7b-instruct      0.600   \n",
      "11   variable_2.0.json  mistralai/mistral-small-24b-instruct-2501      0.500   \n",
      "12   variable_2.0.json                        openai/gpt-4.1-mini      0.500   \n",
      "13   variable_2.0.json                         openai/gpt-4o-mini      0.500   \n",
      "14  variable_28.0.json      deepseek/deepseek-r1-distill-qwen-14b      0.667   \n",
      "15  variable_28.0.json   meta-llama/llama-3.2-11b-vision-instruct      0.600   \n",
      "16  variable_28.0.json          meta-llama/llama-3.3-70b-instruct      0.333   \n",
      "17  variable_28.0.json              mistralai/mistral-7b-instruct      0.333   \n",
      "18  variable_28.0.json  mistralai/mistral-small-24b-instruct-2501      0.429   \n",
      "19  variable_28.0.json                        openai/gpt-4.1-mini      0.333   \n",
      "20  variable_28.0.json                         openai/gpt-4o-mini      0.400   \n",
      "21   variable_3.0.json      deepseek/deepseek-r1-distill-qwen-14b      0.333   \n",
      "22   variable_3.0.json   meta-llama/llama-3.2-11b-vision-instruct      0.500   \n",
      "23   variable_3.0.json          meta-llama/llama-3.3-70b-instruct      0.286   \n",
      "24   variable_3.0.json              mistralai/mistral-7b-instruct      0.500   \n",
      "25   variable_3.0.json  mistralai/mistral-small-24b-instruct-2501      0.167   \n",
      "26   variable_3.0.json                        openai/gpt-4.1-mini      1.000   \n",
      "27   variable_3.0.json                         openai/gpt-4o-mini      0.000   \n",
      "28   variable_5.0.json      deepseek/deepseek-r1-distill-qwen-14b      1.000   \n",
      "29   variable_5.0.json   meta-llama/llama-3.2-11b-vision-instruct      0.000   \n",
      "30   variable_5.0.json          meta-llama/llama-3.3-70b-instruct      0.000   \n",
      "31   variable_5.0.json              mistralai/mistral-7b-instruct      0.333   \n",
      "32   variable_5.0.json  mistralai/mistral-small-24b-instruct-2501      0.000   \n",
      "33   variable_5.0.json                        openai/gpt-4.1-mini      0.667   \n",
      "34   variable_5.0.json                         openai/gpt-4o-mini      1.000   \n",
      "\n",
      "    Recall     F1  \n",
      "0    0.167  0.250  \n",
      "1    0.000  0.000  \n",
      "2    0.167  0.286  \n",
      "3    0.333  0.364  \n",
      "4    0.500  0.545  \n",
      "5    0.333  0.500  \n",
      "6    0.333  0.364  \n",
      "7    0.500  0.500  \n",
      "8    0.000  0.000  \n",
      "9    0.500  0.545  \n",
      "10   0.500  0.545  \n",
      "11   0.500  0.500  \n",
      "12   0.500  0.500  \n",
      "13   0.500  0.500  \n",
      "14   0.800  0.727  \n",
      "15   0.600  0.600  \n",
      "16   0.400  0.364  \n",
      "17   0.400  0.364  \n",
      "18   0.600  0.500  \n",
      "19   0.400  0.364  \n",
      "20   0.400  0.400  \n",
      "21   0.250  0.286  \n",
      "22   0.250  0.333  \n",
      "23   0.500  0.364  \n",
      "24   0.250  0.333  \n",
      "25   0.250  0.200  \n",
      "26   0.250  0.400  \n",
      "27   0.000  0.000  \n",
      "28   0.143  0.250  \n",
      "29   0.000  0.000  \n",
      "30   0.000  0.000  \n",
      "31   0.143  0.200  \n",
      "32   0.000  0.000  \n",
      "33   0.286  0.400  \n",
      "34   0.143  0.250  \n",
      "\n",
      "=== Per-Model Averages (Overall Performance) ===\n",
      "\n",
      "                                       Model  Precision  Recall     F1\n",
      "0      deepseek/deepseek-r1-distill-qwen-14b      0.600   0.372  0.403\n",
      "1   meta-llama/llama-3.2-11b-vision-instruct      0.220   0.170  0.187\n",
      "2          meta-llama/llama-3.3-70b-instruct      0.444   0.313  0.312\n",
      "3              mistralai/mistral-7b-instruct      0.433   0.325  0.361\n",
      "4  mistralai/mistral-small-24b-instruct-2501      0.339   0.370  0.349\n",
      "5                        openai/gpt-4.1-mini      0.700   0.354  0.433\n",
      "6                         openai/gpt-4o-mini      0.460   0.275  0.303\n"
     ]
    }
   ],
   "source": [
    "# 9) Create a DataFrame with aggregated results\n",
    "df_results = pd.DataFrame(all_rows)\n",
    "print(\"\\n=== Final Results DataFrame ===\\n\")\n",
    "print(df_results)\n",
    "\n",
    "# Group by [File, Model] to see average metrics per file-model combo\n",
    "summary = df_results.groupby([\"File\", \"Model\"]).agg({\n",
    "    \"Precision\": \"mean\",\n",
    "    \"Recall\": \"mean\",\n",
    "    \"F1\": \"mean\"\n",
    "}).reset_index()\n",
    "summary = summary.round(3)\n",
    "\n",
    "print(\"\\n=== Summary (Grouped by File, Model) ===\\n\")\n",
    "print(summary)\n",
    "\n",
    "# 10) Compute average metrics for each model (across all files)\n",
    "model_summary = df_results.groupby(\"Model\").agg({\n",
    "    \"Precision\": \"mean\",\n",
    "    \"Recall\": \"mean\",\n",
    "    \"F1\": \"mean\"\n",
    "}).reset_index()\n",
    "model_summary = model_summary.round(3)\n",
    "\n",
    "print(\"\\n=== Per-Model Averages (Overall Performance) ===\\n\")\n",
    "print(model_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d9a186b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ground Truth vs. LLM Output Details ===\n",
      "\n",
      "File: variable_15.0.json\n",
      "Model: mistralai/mistral-7b-instruct\n",
      "Variable: Foraminifera, planktic, size\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"size\", \"ObjectOfInterest (Label)\": \"foraminfers\", \"Matrix (Label)\": \"sediment\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"planctonic\", \"surface\"], \"Constraint component\": [\"foraminfers\", \"sediment\"], \"Applicable units of measure\": \"\\u00b5m\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Size of planktic foraminifers in surface sediments\", \"Definition\": \"Size of planktic foraminifers found in surface sediments, as reported in the study at https://doi.pangaea.de/10.1594/PANGAEA.126730\", \"Statistical Modifier (Label)\": \"dimension\", \"Property (Label)\": \"size\", \"ObjectOfInterest (Label)\": \"foraminifers\", \"Matrix (Label)\": \"surface sediments\", \"Matrix (System)\": \"marine\", \"ContextObject (Label)\": \"sediment core\", \"constraint\": \"planktic\", \"Constraint component\": [\"foraminifers\", \"size\"], \"Applicable units of measure\": \"mm\"}\n",
      "--------------------------------------------------\n",
      "File: variable_15.0.json\n",
      "Model: mistralai/mistral-small-24b-instruct-2501\n",
      "Variable: Foraminifera, planktic, size\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"size\", \"ObjectOfInterest (Label)\": \"foraminfers\", \"Matrix (Label)\": \"sediment\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"planctonic\", \"surface\"], \"Constraint component\": [\"foraminfers\", \"sediment\"], \"Applicable units of measure\": \"\\u00b5m\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Foraminifera, planktic, size\", \"Definition\": \"Size of planktic foraminifers in surface sediments.\", \"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"size\", \"ObjectOfInterest (Label)\": \"foraminifera\", \"Matrix (Label)\": \"sediment\", \"Matrix (System)\": \"surface\", \"ContextObject (Label)\": \"planktic\", \"constraint\": [\"in surface sediments\", \"planktic\"], \"Constraint component\": [\"foraminifera\", \"size\"], \"Applicable units of measure\": \"\\u00b5m\"}\n",
      "--------------------------------------------------\n",
      "File: variable_15.0.json\n",
      "Model: meta-llama/llama-3.2-11b-vision-instruct\n",
      "Variable: Foraminifera, planktic, size\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"size\", \"ObjectOfInterest (Label)\": \"foraminfers\", \"Matrix (Label)\": \"sediment\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"planctonic\", \"surface\"], \"Constraint component\": [\"foraminfers\", \"sediment\"], \"Applicable units of measure\": \"\\u00b5m\"}\n",
      "LLM Output: {}\n",
      "--------------------------------------------------\n",
      "File: variable_15.0.json\n",
      "Model: meta-llama/llama-3.3-70b-instruct\n",
      "Variable: Foraminifera, planktic, size\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"size\", \"ObjectOfInterest (Label)\": \"foraminfers\", \"Matrix (Label)\": \"sediment\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"planctonic\", \"surface\"], \"Constraint component\": [\"foraminfers\", \"sediment\"], \"Applicable units of measure\": \"\\u00b5m\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Foraminifera, planktic, size\", \"Definition\": \"Size of planktic foraminifers in surface sediments\", \"Property (Label)\": \"size\", \"ObjectOfInterest (Label)\": \"planktic foraminifer\", \"Matrix (Label)\": \"surface sediment\", \"Applicable units of measure\": \"micrometers or millimeters\"}\n",
      "--------------------------------------------------\n",
      "File: variable_15.0.json\n",
      "Model: deepseek/deepseek-r1-distill-qwen-14b\n",
      "Variable: Foraminifera, planktic, size\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"size\", \"ObjectOfInterest (Label)\": \"foraminfers\", \"Matrix (Label)\": \"sediment\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"planctonic\", \"surface\"], \"Constraint component\": [\"foraminfers\", \"sediment\"], \"Applicable units of measure\": \"\\u00b5m\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Foraminifera, planktic, size\", \"Definition\": \"Size of planktic foraminifers in surface sediments, as referenced in https://doi.pangaea.de/10.1594/PANGAEA.126730.\", \"Property (Label)\": \"size\", \"ObjectOfInterest (Label)\": \"planktic foraminifers\", \"Matrix (Label)\": \"surface sediment\", \"ContextObject (Label)\": \"ocean\", \"constraint\": [\"planktic\", \"surface sediment\"], \"Constraint component\": [\"planktic foraminifers\", \"surface sediment\"], \"Applicable units of measure\": \"\\u03bcm\"}\n",
      "--------------------------------------------------\n",
      "File: variable_15.0.json\n",
      "Model: openai/gpt-4o-mini\n",
      "Variable: Foraminifera, planktic, size\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"size\", \"ObjectOfInterest (Label)\": \"foraminfers\", \"Matrix (Label)\": \"sediment\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"planctonic\", \"surface\"], \"Constraint component\": [\"foraminfers\", \"sediment\"], \"Applicable units of measure\": \"\\u00b5m\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Size of planktic foraminifers in surface sediments\", \"Definition\": \"The measurement of the size of planktic foraminifers found in surface sediments, which can provide insights into past oceanic conditions.\", \"Statistical Modifier (Label)\": \"mean size\", \"Property (Label)\": \"size\", \"ObjectOfInterest (Label)\": \"planktic foraminifers\", \"Matrix (Label)\": \"surface sediments\", \"Matrix (System)\": \"marine environment\", \"ContextObject (Label)\": \"sediment sample\", \"constraint\": [\"measured in surface sediments\", \"indicative of paleoceanographic conditions\"], \"Constraint component\": [\"planktic foraminifers\", \"size\"], \"Applicable units of measure\": \"\\u00b5m\"}\n",
      "--------------------------------------------------\n",
      "File: variable_15.0.json\n",
      "Model: openai/gpt-4.1-mini\n",
      "Variable: Foraminifera, planktic, size\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"size\", \"ObjectOfInterest (Label)\": \"foraminfers\", \"Matrix (Label)\": \"sediment\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"planctonic\", \"surface\"], \"Constraint component\": [\"foraminfers\", \"sediment\"], \"Applicable units of measure\": \"\\u00b5m\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Foraminifera, planktic, size\", \"Definition\": \"Size of planktic foraminifers measured in surface sediments, as reported in https://doi.pangaea.de/10.1594/PANGAEA.126730.\", \"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"size\", \"ObjectOfInterest (Label)\": \"planktic foraminifer\", \"Matrix (Label)\": \"surface sediment\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": \"\", \"Constraint component\": \"\", \"Applicable units of measure\": \"\\u00b5m\"}\n",
      "--------------------------------------------------\n",
      "File: variable_2.0.json\n",
      "Model: mistralai/mistral-7b-instruct\n",
      "Variable: Air daily maximum temperature\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"daily\", \"1,7 m aboveground\"], \"Constraint component\": [\"maximum\", \"air\"], \"Applicable units of measure\": \"Celsius\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Air daily maximum temperature at 1.7 meters\", \"Definition\": \"Temperature of the air in a height of 1.7 meters, representing the daily maximum.\", \"Statistical Modifier (Label)\": \"maximum\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"ContextObject (Label)\": \"height\", \"ContextObject (Value)\": \"1.7 meters\", \"Applicable units of measure\": \"\\u00b0C\"}\n",
      "--------------------------------------------------\n",
      "File: variable_2.0.json\n",
      "Model: mistralai/mistral-small-24b-instruct-2501\n",
      "Variable: Air daily maximum temperature\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"daily\", \"1,7 m aboveground\"], \"Constraint component\": [\"maximum\", \"air\"], \"Applicable units of measure\": \"Celsius\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Air daily maximum temperature\", \"Definition\": \"Temperature of the air at a height of 1.7 meters, measured as the daily maximum.\", \"Statistical Modifier (Label)\": \"daily maximum\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"environment\", \"ContextObject (Label)\": \"height\", \"constraint\": [\"at a height of 1.7 meters\"], \"Constraint component\": [\"air\", \"temperature\"], \"Applicable units of measure\": \"\\u00b0C\"}\n",
      "--------------------------------------------------\n",
      "File: variable_2.0.json\n",
      "Model: meta-llama/llama-3.2-11b-vision-instruct\n",
      "Variable: Air daily maximum temperature\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"daily\", \"1,7 m aboveground\"], \"Constraint component\": [\"maximum\", \"air\"], \"Applicable units of measure\": \"Celsius\"}\n",
      "LLM Output: {}\n",
      "--------------------------------------------------\n",
      "File: variable_2.0.json\n",
      "Model: meta-llama/llama-3.3-70b-instruct\n",
      "Variable: Air daily maximum temperature\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"daily\", \"1,7 m aboveground\"], \"Constraint component\": [\"maximum\", \"air\"], \"Applicable units of measure\": \"Celsius\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Air daily maximum temperature\", \"Definition\": \"Temperature of the air at a height of 1.7 meters, daily maximum\", \"Statistical Modifier (Label)\": \"daily maximum\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"surface\", \"constraint\": [\"at 1.7 meters height\"], \"Constraint component\": [\"air\", \"temperature\"], \"Applicable units of measure\": \"\\u00b0C\"}\n",
      "--------------------------------------------------\n",
      "File: variable_2.0.json\n",
      "Model: deepseek/deepseek-r1-distill-qwen-14b\n",
      "Variable: Air daily maximum temperature\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"daily\", \"1,7 m aboveground\"], \"Constraint component\": [\"maximum\", \"air\"], \"Applicable units of measure\": \"Celsius\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Air daily maximum temperature\", \"Definition\": \"Temperature of the air at a height of 1.7 meters, measured as the maximum value during a 24-hour period.\", \"Statistical Modifier (Label)\": \"maximum\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"atmosphere\", \"ContextObject (Label)\": \"height\", \"constraint\": [\"at a height of 1.7 meters\", \"daily maximum\"], \"Constraint component\": [\"air\", \"height\"], \"Applicable units of measure\": \"\\u00b0C\"}\n",
      "--------------------------------------------------\n",
      "File: variable_2.0.json\n",
      "Model: openai/gpt-4o-mini\n",
      "Variable: Air daily maximum temperature\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"daily\", \"1,7 m aboveground\"], \"Constraint component\": [\"maximum\", \"air\"], \"Applicable units of measure\": \"Celsius\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Air daily maximum temperature\", \"Definition\": \"The maximum temperature of the air measured at a height of 1.7 meters over a 24-hour period.\", \"Statistical Modifier (Label)\": \"daily maximum\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"environment\", \"ContextObject (Label)\": \"weather station\", \"constraint\": [\"measured at 1.7 meters\", \"over a 24-hour period\"], \"Constraint component\": [\"air\", \"temperature\"], \"Applicable units of measure\": \"\\u00b0C\"}\n",
      "--------------------------------------------------\n",
      "File: variable_2.0.json\n",
      "Model: openai/gpt-4.1-mini\n",
      "Variable: Air daily maximum temperature\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"daily\", \"1,7 m aboveground\"], \"Constraint component\": [\"maximum\", \"air\"], \"Applicable units of measure\": \"Celsius\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Air daily maximum temperature\", \"Definition\": \"Temperature of the air measured at a height of 1.7 meters, representing the daily maximum value.\", \"Statistical Modifier (Label)\": \"daily maximum\", \"Property (Label)\": \"temperature\", \"ObjectOfInterest (Label)\": \"air\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"terrestrial environment\", \"ContextObject (Label)\": \"height of 1.7 meter\", \"constraint\": [\"measured at 1.7 meter height\", \"daily maximum value\"], \"Constraint component\": [\"air\", \"temperature\"], \"Applicable units of measure\": \"\\u00b0C\"}\n",
      "--------------------------------------------------\n",
      "File: variable_5.0.json\n",
      "Model: mistralai/mistral-7b-instruct\n",
      "Variable: Atmosphere optical thickness of particulate organic matter ambient aerosol\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"optical depth\", \"ObjectOfInterest (Label)\": \"organic matter\", \"Matrix (Label)\": \"aerosol particle\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"atmosphere\", \"constraint\": \"at 550 nm wavelength\", \"Constraint component\": \"optical depth\", \"Applicable units of measure\": \"dimensionless\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Atmosphere optical thickness of particulate organic matter ambient aerosol\", \"Definition\": \"Atmospheric optical thickness of particulate organic matter at 550nm under ambient conditions.\", \"Statistical Modifier (Label)\": \"optical thickness\", \"Property (Label)\": \"absorption coefficient\", \"ObjectOfInterest (Label)\": \"particulate organic matter\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"aerosol\", \"ContextObject (Label)\": \"ambient\", \"constraint\": [\"at 550nm\"], \"Constraint component\": [\"atmospheric optical thickness\", \"absorption coefficient\"], \"Applicable units of measure\": \"dimensionless\"}\n",
      "--------------------------------------------------\n",
      "File: variable_5.0.json\n",
      "Model: mistralai/mistral-small-24b-instruct-2501\n",
      "Variable: Atmosphere optical thickness of particulate organic matter ambient aerosol\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"optical depth\", \"ObjectOfInterest (Label)\": \"organic matter\", \"Matrix (Label)\": \"aerosol particle\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"atmosphere\", \"constraint\": \"at 550 nm wavelength\", \"Constraint component\": \"optical depth\", \"Applicable units of measure\": \"dimensionless\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Atmosphere optical thickness of particulate organic matter ambient aerosol\", \"Definition\": \"Atmospheric optical thickness of particulate organic matter at 550nm under ambient conditions.\", \"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"optical thickness\", \"ObjectOfInterest (Label)\": \"particulate organic matter\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"aerosol\", \"constraint\": [\"at 550nm\", \"under ambient conditions\"], \"Constraint component\": [\"particulate organic matter\", \"optical thickness\"], \"Applicable units of measure\": \"\"}\n",
      "--------------------------------------------------\n",
      "File: variable_5.0.json\n",
      "Model: meta-llama/llama-3.2-11b-vision-instruct\n",
      "Variable: Atmosphere optical thickness of particulate organic matter ambient aerosol\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"optical depth\", \"ObjectOfInterest (Label)\": \"organic matter\", \"Matrix (Label)\": \"aerosol particle\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"atmosphere\", \"constraint\": \"at 550 nm wavelength\", \"Constraint component\": \"optical depth\", \"Applicable units of measure\": \"dimensionless\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Atmosphere optical thickness of particulate organic matter ambient aerosol\", \"Definition\": \"Atmospheric optical thickness of particulate organic matter at 550nm under ambient conditions.\", \"Property (Label)\": \"optical thickness\", \"ObjectOfInterest (Label)\": \"particulate organic matter\", \"Matrix (Label)\": \"atmosphere\", \"Applicable units of measure\": \"...\"}\n",
      "--------------------------------------------------\n",
      "File: variable_5.0.json\n",
      "Model: meta-llama/llama-3.3-70b-instruct\n",
      "Variable: Atmosphere optical thickness of particulate organic matter ambient aerosol\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"optical depth\", \"ObjectOfInterest (Label)\": \"organic matter\", \"Matrix (Label)\": \"aerosol particle\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"atmosphere\", \"constraint\": \"at 550 nm wavelength\", \"Constraint component\": \"optical depth\", \"Applicable units of measure\": \"dimensionless\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Atmosphere optical thickness of particulate organic matter ambient aerosol\", \"Definition\": \"Atmospheric optical thickness of particulate organic matter at 550nm under ambient conditions.\", \"Property (Label)\": \"optical thickness\", \"ObjectOfInterest (Label)\": \"particulate organic matter\", \"Matrix (Label)\": \"atmosphere\", \"constraint\": [\"at 550nm\", \"under ambient conditions\"], \"Constraint component\": [\"particulate organic matter\", \"optical thickness\"], \"Applicable units of measure\": \"unitless or dimensionless\"}\n",
      "--------------------------------------------------\n",
      "File: variable_5.0.json\n",
      "Model: deepseek/deepseek-r1-distill-qwen-14b\n",
      "Variable: Atmosphere optical thickness of particulate organic matter ambient aerosol\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"optical depth\", \"ObjectOfInterest (Label)\": \"organic matter\", \"Matrix (Label)\": \"aerosol particle\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"atmosphere\", \"constraint\": \"at 550 nm wavelength\", \"Constraint component\": \"optical depth\", \"Applicable units of measure\": \"dimensionless\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Atmosphere optical thickness of particulate organic matter ambient aerosol\", \"Definition\": \"Optical thickness quantifying the absorption and scattering of light by particulate organic matter in the atmosphere at a wavelength of 550 nm under ambient conditions.\", \"Property (Label)\": \"optical thickness\", \"ObjectOfInterest (Label)\": \"particulate organic matter\", \"Matrix (Label)\": \"atmosphere\", \"ContextObject (Label)\": \"ambient aerosol\", \"constraint\": [\"at 550 nm\", \"under ambient conditions\"], \"Constraint component\": [\"atmosphere\", \"optical thickness\"], \"Applicable units of measure\": \"dimensionless\"}\n",
      "--------------------------------------------------\n",
      "File: variable_5.0.json\n",
      "Model: openai/gpt-4o-mini\n",
      "Variable: Atmosphere optical thickness of particulate organic matter ambient aerosol\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"optical depth\", \"ObjectOfInterest (Label)\": \"organic matter\", \"Matrix (Label)\": \"aerosol particle\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"atmosphere\", \"constraint\": \"at 550 nm wavelength\", \"Constraint component\": \"optical depth\", \"Applicable units of measure\": \"dimensionless\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Atmosphere optical thickness of particulate organic matter ambient aerosol\", \"Definition\": \"Atmospheric optical thickness of particulate organic matter at 550nm under ambient conditions.\", \"Property (Label)\": \"optical thickness\", \"ObjectOfInterest (Label)\": \"particulate organic matter\", \"Matrix (Label)\": \"atmosphere\", \"ContextObject (Label)\": \"ambient aerosol\", \"Applicable units of measure\": \"dimensionless\"}\n",
      "--------------------------------------------------\n",
      "File: variable_5.0.json\n",
      "Model: openai/gpt-4.1-mini\n",
      "Variable: Atmosphere optical thickness of particulate organic matter ambient aerosol\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"optical depth\", \"ObjectOfInterest (Label)\": \"organic matter\", \"Matrix (Label)\": \"aerosol particle\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"atmosphere\", \"constraint\": \"at 550 nm wavelength\", \"Constraint component\": \"optical depth\", \"Applicable units of measure\": \"dimensionless\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Atmosphere optical thickness of particulate organic matter ambient aerosol\", \"Definition\": \"Atmospheric optical thickness of particulate organic matter at 550nm under ambient conditions.\", \"Property (Label)\": \"optical thickness\", \"ObjectOfInterest (Label)\": \"particulate organic matter\", \"Matrix (Label)\": \"ambient aerosol\", \"Matrix (System)\": \"atmosphere\", \"ContextObject (Label)\": \"atmosphere\", \"constraint\": [\"measured at 550 nm\", \"under ambient conditions\"], \"Constraint component\": [\"optical thickness\", \"particulate organic matter\"], \"Applicable units of measure\": \"dimensionless\"}\n",
      "--------------------------------------------------\n",
      "File: variable_3.0.json\n",
      "Model: mistralai/mistral-7b-instruct\n",
      "Variable: Cloud cover\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"cloud\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": \"\", \"Constraint component\": \"\", \"Applicable units of measure\": \"unitless (okta)\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Cloud cover\", \"Definition\": \"The amount of sky estimated to be covered by all cloud types (total cloud amount). The estimate is made to the nearest okta (eighth) and is reported on a scale which is essentially one of the nearest eighth, except that figures 0 and 8 on the scale signify a completely clear and cloudy sky, respectively, with consequent adjustment to the adjacent 1 and 7 okta intervals.\", \"Statistical Modifier (Label)\": \"Estimated\", \"Property (Label)\": \"Cloud cover\", \"ObjectOfInterest (Label)\": \"Cloud\", \"Matrix (Label)\": \"Sky\", \"Applicable units of measure\": \"Okta (eighth)\"}\n",
      "--------------------------------------------------\n",
      "File: variable_3.0.json\n",
      "Model: mistralai/mistral-small-24b-instruct-2501\n",
      "Variable: Cloud cover\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"cloud\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": \"\", \"Constraint component\": \"\", \"Applicable units of measure\": \"unitless (okta)\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Cloud cover\", \"Definition\": \"The amount of sky estimated to be covered by all cloud types (total cloud amount). The estimate is made to the nearest okta (eighth) and is reported on a scale which is essentially one of the nearest eighth, except that figures 0 and 8 on the scale signify a completely clear and cloudy sky, respectively, with consequent adjustment to the adjacent 1 and 7 okta intervals.\", \"Statistical Modifier (Label)\": \"total\", \"Property (Label)\": \"fractional coverage\", \"ObjectOfInterest (Label)\": \"cloud\", \"Matrix (Label)\": \"sky\", \"Matrix (System)\": \"atmosphere\", \"ContextObject (Label)\": \"sky\", \"constraint\": [\"estimated to the nearest okta\", \"reported on a scale of 0 to 8 oktas\", \"0 okta signifies a completely clear sky\", \"8 okta signifies a completely cloudy sky\"], \"Constraint component\": [\"cloud\", \"fractional coverage\"], \"Applicable units of measure\": \"okta\"}\n",
      "--------------------------------------------------\n",
      "File: variable_3.0.json\n",
      "Model: meta-llama/llama-3.2-11b-vision-instruct\n",
      "Variable: Cloud cover\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"cloud\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": \"\", \"Constraint component\": \"\", \"Applicable units of measure\": \"unitless (okta)\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Cloud cover\", \"Definition\": \"The amount of sky estimated to be covered by all cloud types (total cloud amount). The estimate is made to the nearest okta (eighth) and is reported on a scale which is essentially one of the nearest eighth, except that figures 0 and 8 on the scale signify a completely clear and cloudy sky, respectively, with consequent adjustment to the adjacent 1 and 7 okta intervals.\", \"Statistical Modifier (Label)\": \"estimated\", \"Property (Label)\": \"fraction of area\", \"ObjectOfInterest (Label)\": \"sky\", \"Applicable units of measure\": \"okta\"}\n",
      "--------------------------------------------------\n",
      "File: variable_3.0.json\n",
      "Model: meta-llama/llama-3.3-70b-instruct\n",
      "Variable: Cloud cover\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"cloud\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": \"\", \"Constraint component\": \"\", \"Applicable units of measure\": \"unitless (okta)\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Cloud cover\", \"Definition\": \"The amount of sky estimated to be covered by all cloud types (total cloud amount).\", \"Statistical Modifier (Label)\": \"average\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"cloud\", \"Matrix (Label)\": \"sky\", \"Matrix (System)\": \"atmosphere\", \"ContextObject (Label)\": \"observation location\", \"constraint\": [\"estimated to the nearest okta\", \"reported on a scale of eighths\"], \"Constraint component\": [\"cloud\", \"area fraction\"], \"Applicable units of measure\": \"okta (eighths)\"}\n",
      "--------------------------------------------------\n",
      "File: variable_3.0.json\n",
      "Model: deepseek/deepseek-r1-distill-qwen-14b\n",
      "Variable: Cloud cover\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"cloud\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": \"\", \"Constraint component\": \"\", \"Applicable units of measure\": \"unitless (okta)\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Cloud cover\", \"Definition\": \"The amount of sky estimated to be covered by all cloud types (total cloud amount). The estimate is made to the nearest okta (eighth) and is reported on a scale which is essentially one of the nearest eighth, except that figures 0 and 8 on the scale signify a completely clear and cloudy sky, respectively, with consequent adjustment to the adjacent 1 and 7 okta intervals.\", \"Property (Label)\": \"coverage\", \"ObjectOfInterest (Label)\": \"sky\", \"Matrix (Label)\": \"atmosphere\", \"constraint\": [\"estimated to the nearest okta\", \"reported on a scale from 0 to 8\", \"0 signifies completely clear sky\", \"8 signifies completely cloudy sky\"], \"Constraint component\": [\"cloud cover\", \"okta scale\"], \"Applicable units of measure\": \"okta\"}\n",
      "--------------------------------------------------\n",
      "File: variable_3.0.json\n",
      "Model: openai/gpt-4o-mini\n",
      "Variable: Cloud cover\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"cloud\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": \"\", \"Constraint component\": \"\", \"Applicable units of measure\": \"unitless (okta)\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Cloud cover\", \"Definition\": \"The amount of sky estimated to be covered by all cloud types (total cloud amount), reported on a scale of okta (eighths), where 0 signifies a completely clear sky and 8 signifies a completely cloudy sky.\", \"Property (Label)\": \"cloud amount\", \"ObjectOfInterest (Label)\": \"clouds\", \"Applicable units of measure\": \"okta\"}\n",
      "--------------------------------------------------\n",
      "File: variable_3.0.json\n",
      "Model: openai/gpt-4.1-mini\n",
      "Variable: Cloud cover\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"area fraction\", \"ObjectOfInterest (Label)\": \"cloud\", \"Matrix (Label)\": \"atmosphere\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": \"\", \"Constraint component\": \"\", \"Applicable units of measure\": \"unitless (okta)\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Cloud cover\", \"Definition\": \"The amount of sky estimated to be covered by all cloud types (total cloud amount). The estimate is made to the nearest okta (eighth) and is reported on a scale which is essentially one of the nearest eighth, except that figures 0 and 8 on the scale signify a completely clear and cloudy sky, respectively, with consequent adjustment to the adjacent 1 and 7 okta intervals.\", \"Property (Label)\": \"fractional coverage\", \"ObjectOfInterest (Label)\": \"cloud\", \"Matrix (Label)\": \"sky\", \"Applicable units of measure\": \"okta\"}\n",
      "--------------------------------------------------\n",
      "File: variable_28.0.json\n",
      "Model: mistralai/mistral-7b-instruct\n",
      "Variable: Overnight stays in 3-star hotel near the sea shore\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"count\", \"ObjectOfInterest (Label)\": \"overnight stay\", \"Matrix (Label)\": \"hotel\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"3 star\", \"near the sea shore\"], \"Constraint component\": \"hotel\", \"Applicable units of measure\": \"\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Overnight stays in 3-star hotel near the sea shore\", \"Definition\": \"Number of nights spent in a 3-star hotel located near the sea shore.\", \"Statistical Modifier (Label)\": \"count\", \"Property (Label)\": \"duration\", \"ObjectOfInterest (Label)\": \"overnight stay\", \"Matrix (Label)\": \"hotel\", \"Matrix (System)\": \"accommodation\", \"ContextObject (Label)\": \"3-star hotel\", \"constraint\": [\"near the sea shore\"], \"Constraint component\": [\"hotel\", \"duration\"], \"Applicable units of measure\": \"nights\"}\n",
      "--------------------------------------------------\n",
      "File: variable_28.0.json\n",
      "Model: mistralai/mistral-small-24b-instruct-2501\n",
      "Variable: Overnight stays in 3-star hotel near the sea shore\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"count\", \"ObjectOfInterest (Label)\": \"overnight stay\", \"Matrix (Label)\": \"hotel\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"3 star\", \"near the sea shore\"], \"Constraint component\": \"hotel\", \"Applicable units of measure\": \"\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Overnight stays in 3-star hotel near the sea shore\", \"Definition\": \"Number of nights in a 3-star hotel near the sea shore.\", \"Statistical Modifier (Label)\": \"count\", \"Property (Label)\": \"number of nights\", \"ObjectOfInterest (Label)\": \"overnight stay\", \"Matrix (Label)\": \"hotel\", \"Matrix (System)\": \"accommodation\", \"ContextObject (Label)\": \"sea shore\", \"constraint\": [\"3-star\", \"near the sea shore\"], \"Constraint component\": [\"hotel\", \"number of nights\"], \"Applicable units of measure\": \"nights\"}\n",
      "--------------------------------------------------\n",
      "File: variable_28.0.json\n",
      "Model: meta-llama/llama-3.2-11b-vision-instruct\n",
      "Variable: Overnight stays in 3-star hotel near the sea shore\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"count\", \"ObjectOfInterest (Label)\": \"overnight stay\", \"Matrix (Label)\": \"hotel\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"3 star\", \"near the sea shore\"], \"Constraint component\": \"hotel\", \"Applicable units of measure\": \"\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Overnight stays in 3-star hotel near the sea shore\", \"Definition\": \"Number of nights in a 3-star hotel near the sea shore\", \"Property (Label)\": \"quantity\", \"ObjectOfInterest (Label)\": \"overnight stay\", \"Matrix (Label)\": \"hotel\", \"Matrix (System)\": \"accommodation\", \"constraint\": [\"3-star\", \"near the sea shore\"], \"Constraint component\": [\"hotel\", \"overnight stay\"], \"Applicable units of measure\": \"nights\"}\n",
      "--------------------------------------------------\n",
      "File: variable_28.0.json\n",
      "Model: meta-llama/llama-3.3-70b-instruct\n",
      "Variable: Overnight stays in 3-star hotel near the sea shore\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"count\", \"ObjectOfInterest (Label)\": \"overnight stay\", \"Matrix (Label)\": \"hotel\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"3 star\", \"near the sea shore\"], \"Constraint component\": \"hotel\", \"Applicable units of measure\": \"\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Overnight stays in 3-star hotel near the sea shore\", \"Definition\": \"Number of nights in a 3-star hotel near the sea shore\", \"Statistical Modifier (Label)\": \"count\", \"Property (Label)\": \"duration\", \"ObjectOfInterest (Label)\": \"overnight stay\", \"Matrix (Label)\": \"hotel\", \"Matrix (System)\": \"tourism\", \"ContextObject (Label)\": \"sea shore\", \"constraint\": [\"3-star hotel\", \"near the sea shore\"], \"Constraint component\": [\"hotel\", \"location\"], \"Applicable units of measure\": \"nights\"}\n",
      "--------------------------------------------------\n",
      "File: variable_28.0.json\n",
      "Model: deepseek/deepseek-r1-distill-qwen-14b\n",
      "Variable: Overnight stays in 3-star hotel near the sea shore\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"count\", \"ObjectOfInterest (Label)\": \"overnight stay\", \"Matrix (Label)\": \"hotel\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"3 star\", \"near the sea shore\"], \"Constraint component\": \"hotel\", \"Applicable units of measure\": \"\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Overnight stays in 3-star hotel near the sea shore\", \"Definition\": \"The number of nights spent in a 3-star hotel located near the sea shore.\", \"Property (Label)\": \"count\", \"ObjectOfInterest (Label)\": \"overnight stay\", \"Matrix (Label)\": \"hotel\", \"Matrix (System)\": \"hospitality\", \"constraint\": [\"3-star\", \"near the sea shore\"], \"Constraint component\": [\"hotel\", \"3-star\", \"sea shore\"], \"Applicable units of measure\": \"nights\"}\n",
      "--------------------------------------------------\n",
      "File: variable_28.0.json\n",
      "Model: openai/gpt-4o-mini\n",
      "Variable: Overnight stays in 3-star hotel near the sea shore\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"count\", \"ObjectOfInterest (Label)\": \"overnight stay\", \"Matrix (Label)\": \"hotel\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"3 star\", \"near the sea shore\"], \"Constraint component\": \"hotel\", \"Applicable units of measure\": \"\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Overnight stays in 3-star hotel near the sea shore\", \"Definition\": \"Number of nights spent in a 3-star hotel located near the sea shore.\", \"Property (Label)\": \"count\", \"ObjectOfInterest (Label)\": \"overnight stays\", \"Matrix (Label)\": \"hotel accommodation\", \"Matrix (System)\": \"tourism\", \"ContextObject (Label)\": \"3-star hotel\", \"constraint\": [\"near the sea shore\"], \"Constraint component\": [\"hotel accommodation\", \"overnight stays\"], \"Applicable units of measure\": \"nights\"}\n",
      "--------------------------------------------------\n",
      "File: variable_28.0.json\n",
      "Model: openai/gpt-4.1-mini\n",
      "Variable: Overnight stays in 3-star hotel near the sea shore\n",
      "Ground Truth: {\"Statistical Modifier (Label)\": \"\", \"Property (Label)\": \"count\", \"ObjectOfInterest (Label)\": \"overnight stay\", \"Matrix (Label)\": \"hotel\", \"Matrix (System)\": \"\", \"ContextObject (Label)\": \"\", \"constraint\": [\"3 star\", \"near the sea shore\"], \"Constraint component\": \"hotel\", \"Applicable units of measure\": \"\"}\n",
      "LLM Output: {\"Provided Variable Name\": \"Overnight stays in 3-star hotel near the sea shore\", \"Definition\": \"Number of nights spent by guests in a 3-star hotel located near the sea shore.\", \"Statistical Modifier (Label)\": \"count\", \"Property (Label)\": \"number of overnight stays\", \"ObjectOfInterest (Label)\": \"overnight stay\", \"Matrix (Label)\": \"hotel\", \"Matrix (System)\": \"tourism accommodation\", \"ContextObject (Label)\": \"3-star hotel near the sea shore\", \"constraint\": [\"3-star hotel\", \"near the sea shore\"], \"Constraint component\": [\"hotel\", \"location\"], \"Applicable units of measure\": \"nights\"}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 10) Finally, show ground truth and LLM outputs after the summary\n",
    "print(\"\\n=== Ground Truth vs. LLM Output Details ===\\n\")\n",
    "for idx, row in df_results.iterrows():\n",
    "    print(\"File:\", row[\"File\"])\n",
    "    print(\"Model:\", row[\"Model\"])\n",
    "    print(\"Variable:\", row[\"Variable\"])\n",
    "    print(\"Ground Truth:\", row[\"GroundTruth\"])\n",
    "    print(\"LLM Output:\", row[\"LLMOutput\"])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64051d50",
   "metadata": {},
   "source": [
    "         Model  Precision  Recall     F1\n",
    "0       gpt-4o      0.667   0.425  0.481\n",
    "1  gpt-4o-mini      0.443   0.364  0.369\n",
    "\n",
    "\n",
    "                                      Model  Precision  Recall     F1\n",
    "0     deepseek/deepseek-r1-distill-qwen-14b      0.457   0.223  0.274\n",
    "1  meta-llama/llama-3.2-11b-vision-instruct      0.450   0.230  0.289\n",
    "2             mistralai/mistral-7b-instruct      0.367   0.297  0.321\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "=== Per-Model Averages (Overall Performance) ===\n",
    "\n",
    "                                       Model  Precision  Recall     F1\n",
    "0      deepseek/deepseek-r1-distill-qwen-14b      0.600   0.372  0.403\n",
    "1   meta-llama/llama-3.2-11b-vision-instruct      0.220   0.170  0.187\n",
    "2          meta-llama/llama-3.3-70b-instruct      0.444   0.313  0.312\n",
    "3              mistralai/mistral-7b-instruct      0.433   0.325  0.361\n",
    "4  mistralai/mistral-small-24b-instruct-2501      0.339   0.370  0.349\n",
    "5                        openai/gpt-4.1-mini      0.700   0.354  0.433\n",
    "6                         openai/gpt-4o-mini      0.460   0.275  0.303"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6ce215",
   "metadata": {},
   "source": [
    "          File        Model  Precision  Recall     F1\n",
    "0    var1.json       gpt-4o      1.000   0.500  0.667\n",
    "1    var1.json  gpt-4o-mini      0.333   0.167  0.222\n",
    "2   var17.json       gpt-4o      0.500   0.167  0.250\n",
    "3   var17.json  gpt-4o-mini      0.000   0.000  0.000\n",
    "4    var2.json       gpt-4o      0.600   0.333  0.429\n",
    "5    var2.json  gpt-4o-mini      0.500   0.222  0.308\n",
    "6    var3.json       gpt-4o      0.000   0.000  0.000\n",
    "7    var3.json  gpt-4o-mini      1.000   0.500  0.667\n",
    "8    var4.json       gpt-4o      0.000   0.000  0.000\n",
    "9    var4.json  gpt-4o-mini      0.167   0.167  0.167\n",
    "10   var5.json       gpt-4o      1.000   0.125  0.222\n",
    "11   var5.json  gpt-4o-mini      0.250   0.125  0.167\n",
    "\n",
    "\n",
    "\n",
    "          File        Model  Precision  Recall     F1\n",
    "0    var1.json       gpt-4o      1.000   1.000  1.000\n",
    "1    var1.json  gpt-4o-mini      1.000   1.000  1.000\n",
    "2   var17.json       gpt-4o      0.250   0.333  0.286\n",
    "3   var17.json  gpt-4o-mini      0.000   0.000  0.000\n",
    "4    var2.json       gpt-4o      0.750   0.600  0.667\n",
    "5    var2.json  gpt-4o-mini      0.667   0.400  0.500\n",
    "6    var3.json       gpt-4o      0.000   0.000  0.000\n",
    "7    var3.json  gpt-4o-mini      0.667   0.667  0.667\n",
    "8    var4.json       gpt-4o      0.000   0.000  0.000\n",
    "9    var4.json  gpt-4o-mini      0.500   0.333  0.400\n",
    "10   var5.json       gpt-4o      0.500   0.500  0.500\n",
    "11   var5.json  gpt-4o-mini      1.000   0.500  0.667\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e203eea3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
